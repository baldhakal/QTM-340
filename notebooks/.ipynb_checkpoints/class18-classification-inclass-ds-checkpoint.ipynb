{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'gender': ['w', 'm'], 'obit': ['', ''], 'date':[\"\",\"\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>obit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>w</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender obit date\n",
       "0      w          \n",
       "1      m          "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "match() missing 1 required positional argument: 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-ecee61e2800d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[A-Z][a-z]*[ ][1-9]*[,][ ][1-9]*[\\n][\\n]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[A-Z][a-z]*[ ][1-9]*[,][ ][1-9]*[\\n][\\n]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: match() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "directory = \"../docs/NYT-Obituaries/\"\n",
    "files = glob.glob(f\"{directory}/*.txt\")\n",
    "count = 0\n",
    "for file in files:\n",
    "    text = open(file, encoding='utf-8').read()\n",
    "    date = re.match(\"[A-Z][a-z]*[ ][1-9]*[,][ ][1-9]*[\\n][\\n]\", text)\n",
    "    df.at[count, 'date'] = date\n",
    "    text = re.sub(\"[A-Z][a-z]*[ ][1-9]*[,][ ][1-9]*[\\n][\\n]\",\"\", text)\n",
    "    text = re.sub(\"[OBITUARY]\", \"\", text)\n",
    "    text = re.sub(\"[\\n]\",\"\", text)\n",
    "    df.at[count, 'obit'] = text\n",
    "    count += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "text_file = open('/media/secure_volume/jockers_stopwords.txt')\n",
    "jockers_words = text_file.read().split()\n",
    "new_stopwords = text.ENGLISH_STOP_WORDS.union(jockers_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata\n",
    "meta1 = pd.read_csv('/media/secure_volume/bantamMeta.csv', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process metadata to use in doc-term matrix (dtm)\n",
    "files = (os.listdir('/media/secure_volume/CLASSIFIER_CORPUS_EQUAL_FINAL'))\n",
    "files_final = []\n",
    "for x in files:\n",
    "    x = x[:-4]\n",
    "    ''.join(x)\n",
    "    #print(x)\n",
    "    files_final.append(x)\n",
    "#print(files_final)\n",
    "meta = meta.loc[meta['htid'].isin(files_final)]\n",
    "print(str(len(files_final)))\n",
    "print(str(len(files)))\n",
    "print('meta length is: ' + str(len(meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dtm\n",
    "corpus_path = '/media/secure_volume/CLASSIFIER_CORPUS_EQUAL_FINAL'\n",
    "vectorizer = CountVectorizer(input='filename', encoding='utf8', stop_words = new_stopwords, min_df=40, dtype='float64')\n",
    "dtm = vectorizer.fit_transform(corpus_path + '/' + meta['htid'] + '.txt')\n",
    "vocab = vectorizer.get_feature_names()\n",
    "matrix = dtm.toarray()\n",
    "df = DataFrame(matrix, columns=vocab)\n",
    "print('df shape is: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set classes for logistic regression classification\n",
    "meta = meta.reset_index()\n",
    "meta['CLASS'] = ''\n",
    "meta.ix[meta['imprint'].str.contains('NAL') == True, 'CLASS'] = 0\n",
    "meta.ix[meta['imprint'].str.contains('RH') == True, 'CLASS'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([meta, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE FOR ONE VS ALL CLASSIFICATION\n",
    "#  print(df_final.head())\n",
    "#df_final['PREDICTED'] = np.nan\n",
    "#df_final['PROBS'] = np.nan\n",
    "#print(df_final.head())\n",
    "\n",
    "meta_df = df_final.iloc[:,:7]\n",
    "feat_df = df_final.iloc[:,7:]\n",
    "#print(meta_df.head)\n",
    "\n",
    "meta_df['PROBS'] = np.nan\n",
    "meta_df['PREDICTED'] = np.nan\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', C = 1.0)\n",
    "\n",
    "for this_index in df_final.index.tolist():\n",
    "    title = meta_df.loc[meta_df.index[this_index], 'title'] \n",
    "    CLASS = meta_df.loc[meta_df.index[this_index], 'CLASS']\n",
    "    print(title)\n",
    "    train_index_list = [index_ for index_ in feat_df.index.tolist() if index_ != this_index]\n",
    "\n",
    "    X = feat_df.loc[train_index_list]\n",
    "    y = meta_df.loc[train_index_list, 'CLASS']\n",
    "    TEST_CASE = feat_df.loc[[this_index]]\n",
    "\n",
    "    model.fit(X,y)\n",
    "    prediction = model.predict_proba(TEST_CASE)\n",
    "    predicted = model.predict(TEST_CASE)\n",
    "\n",
    "    meta_df.loc[meta_df.index[this_index], 'PREDICTED'] = predicted\n",
    "    meta_df.loc[meta_df.index[this_index], 'PROBS'] = str(prediction)\n",
    "    print('Class is: ' + str(CLASS) + ' ' + 'prediction is: ' + str(predicted) + ' ' + str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "meta2.to_csv('/media/secure_volume/CLASSIFIER_OUTPUT_MASS_TRADE_1980_2007_5.csv', sep='\\t')\n",
    "\n",
    "\n",
    "canonic_c = 1.0\n",
    "\n",
    "\n",
    "def Ztest(vec1, vec2):\n",
    "\n",
    "    X1, X2 = np.mean(vec1), np.mean(vec2)\n",
    "    sd1, sd2 = np.std(vec1), np.std(vec2)\n",
    "    n1, n2 = len(vec1), len(vec2)\n",
    "\n",
    "    pooledSE = np.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = (X1 - X2)/pooledSE\n",
    "    pval = 2*(norm.sf(abs(z)))\n",
    "\n",
    "    return z, pval\n",
    "\n",
    "def feat_pval_weight(meta_df_, dtm_df_):\n",
    "    \n",
    "    #dtm_df_ = dtm_df_.loc[meta_df_.index.tolist()]\n",
    "    dtm_df_ = normalize_model(dtm_df_, dtm_df_)[0]\n",
    "    #dtm_df_ = dtm_df_.dropna(axis = 1, how='any')\n",
    "\n",
    "    dtm0 = dtm_df_.loc[meta_df_[meta_df_['CLASS']==0].index.tolist()].to_numpy()\n",
    "    dtm1 = dtm_df_.loc[meta_df_[meta_df_['CLASS']==1].index.tolist()].to_numpy()\n",
    "\n",
    "    print(dtm0.shape)\n",
    "    print(dtm1.shape)\n",
    "    pvals = [Ztest(dtm0[ : ,i], dtm1[ : ,i])[1] for i in range(dtm_df_.shape[1])]\n",
    "    clf = LogisticRegression(penalty = 'l1', C = canonic_c, class_weight = 'balanced')\n",
    "    clf.fit(dtm_df_, meta_df_['CLASS']==0)\n",
    "    weights = clf.coef_[0]\n",
    "\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    feature_df['FEAT'] = dtm_df_.columns\n",
    "    feature_df['P_VALUE'] = pvals\n",
    "    feature_df['LR_WEIGHT'] = weights\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "#meta_df2 = df_final2.iloc[:,:7]\n",
    "#feat_df2 = df_final2.iloc[:,7:]\n",
    "sig_thresh = 0.05 / len(df2.columns)\n",
    "\n",
    "feat_df = feat_pval_weight(meta2, df2)\n",
    "print(feat_df.shape)\n",
    "\n",
    "feat_df.to_csv('/media/secure_volume/FEATURES_MASS_TRADE_1980_2007_5.csv')\n",
    "out = feat_df[(feat_df['P_VALUE'] <= sig_thresh)].sort_values('LR_WEIGHT', ascending = True)\n",
    "out1 = out['FEAT'].tolist()\n",
    "for o in out1[0:30]:\n",
    "    print(o)\n",
    "featuresFile = open('/media/secure_volume/FEATURE_LIST_MASS_TRADE_1980_2007_5.txt', 'w')\n",
    "out1 = '\\n'.join(out1) \n",
    "featuresFile.write(str(out1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
