{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, for fun, is the ineffient, un-Pythonic code I used to make the DataFrame for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "d = {'gender': ['', ''], 'obit': ['', ''], 'date':[\"\",\"\"]}\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n",
    "\n",
    "directory = \"../docs/NYT-Obituaries/\"\n",
    "files = glob.glob(f\"{directory}/*.txt\")\n",
    "\n",
    "count = 0\n",
    "for file in files:\n",
    "    text = open(file, encoding='utf-8').read()\n",
    "    p = re.compile(\"[1-9]{4}\")\n",
    "    m = p.search(text)\n",
    "    if m != None:\n",
    "        df.at[count, 'date'] = m.group(0)\n",
    "    else:\n",
    "        df.at[count, 'date'] = \"n/a\"\n",
    "    text = re.sub(\"[A-Z][a-z]*[ ][1-9]*[,][ ][1-9]*[\\n][\\n]\",\"\", text)\n",
    "    text = re.sub(\"[A-Z]{8}\", \"\", text)\n",
    "    text = re.sub(\"[\\n]\",\"\", text)\n",
    "    df.at[count, 'obit'] = text\n",
    "    count += 1\n",
    "df\n",
    "df.to_csv(\"../docs/NYT-Obituaries.csv\", encoding='utf-8', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..docs/jockers_stopwords.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-17b2e8a34fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..docs/jockers_stopwords.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjockers_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjockers_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..docs/jockers_stopwords.txt'"
     ]
    }
   ],
   "source": [
    "# load stopwords\n",
    "text_file = open('..docs/jockers_stopwords.txt')\n",
    "jockers_words = text_file.read().split()\n",
    "new_stopwords = text.ENGLISH_STOP_WORDS.union(jockers_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>obit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hitler Fought Way to Power Unique in Modern Hi...</td>\n",
       "      <td>1945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F. W. Taylor, Expert in Efficiency, Dies BY TH...</td>\n",
       "      <td>1915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>The Life of Chiang Kai-shek: A Leader Who Was ...</td>\n",
       "      <td>1975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Ethel Merman, Queen of Musicals, Dies at 76 By...</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Jim Thorpe Is Dead On West Coast at 64 Special...</td>\n",
       "      <td>1953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>Andres Segovie Is Dead at 94; His Crusade Elev...</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>1</td>\n",
       "      <td>Rita Hayworth, Movie Legend, Dies By ALBIN KRE...</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>June 20, 1993  William Golding Is Dead at 81; ...</td>\n",
       "      <td>1993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>Florenz Ziegfeld Dies in Hollywood After Long ...</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>Stanislavsky Dies in Moscow At 75 By THE ED PR...</td>\n",
       "      <td>1938.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender                                               obit    date\n",
       "0         0  Hitler Fought Way to Power Unique in Modern Hi...  1945.0\n",
       "1         0  F. W. Taylor, Expert in Efficiency, Dies BY TH...  1915.0\n",
       "2         0  The Life of Chiang Kai-shek: A Leader Who Was ...  1975.0\n",
       "3         1  Ethel Merman, Queen of Musicals, Dies at 76 By...  1984.0\n",
       "4         0  Jim Thorpe Is Dead On West Coast at 64 Special...  1953.0\n",
       "..      ...                                                ...     ...\n",
       "373       0  Andres Segovie Is Dead at 94; His Crusade Elev...  1987.0\n",
       "374       1  Rita Hayworth, Movie Legend, Dies By ALBIN KRE...  1987.0\n",
       "375       0  June 20, 1993  William Golding Is Dead at 81; ...  1993.0\n",
       "376       1  Florenz Ziegfeld Dies in Hollywood After Long ...  1932.0\n",
       "377       0  Stanislavsky Dies in Moscow At 75 By THE ED PR...  1938.0\n",
       "\n",
       "[378 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(\"../docs/NYT-Obituaries.csv\", encoding = 'utf-8')\n",
    "meta = meta[[\"gender\", \"obit\", \"date\"]]\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata\n",
    "meta1 = pd.read_csv('/media/secure_volume/bantamMeta.csv', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process metadata to use in doc-term matrix (dtm)\n",
    "files = (os.listdir('/media/secure_volume/CLASSIFIER_CORPUS_EQUAL_FINAL'))\n",
    "files_final = []\n",
    "for x in files:\n",
    "    x = x[:-4]\n",
    "    ''.join(x)\n",
    "    #print(x)\n",
    "    files_final.append(x)\n",
    "#print(files_final)\n",
    "meta = meta.loc[meta['htid'].isin(files_final)]\n",
    "print(str(len(files_final)))\n",
    "print(str(len(files)))\n",
    "print('meta length is: ' + str(len(meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dtm\n",
    "corpus_path = '/media/secure_volume/CLASSIFIER_CORPUS_EQUAL_FINAL'\n",
    "vectorizer = CountVectorizer(input='filename', encoding='utf8', stop_words = new_stopwords, min_df=40, dtype='float64')\n",
    "dtm = vectorizer.fit_transform(corpus_path + '/' + meta['htid'] + '.txt')\n",
    "vocab = vectorizer.get_feature_names()\n",
    "matrix = dtm.toarray()\n",
    "df = DataFrame(matrix, columns=vocab)\n",
    "print('df shape is: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set classes for logistic regression classification\n",
    "meta = meta.reset_index()\n",
    "meta['CLASS'] = ''\n",
    "meta.ix[meta['imprint'].str.contains('NAL') == True, 'CLASS'] = 0\n",
    "meta.ix[meta['imprint'].str.contains('RH') == True, 'CLASS'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([meta, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE FOR ONE VS ALL CLASSIFICATION\n",
    "#  print(df_final.head())\n",
    "#df_final['PREDICTED'] = np.nan\n",
    "#df_final['PROBS'] = np.nan\n",
    "#print(df_final.head())\n",
    "\n",
    "meta_df = df_final.iloc[:,:7]\n",
    "feat_df = df_final.iloc[:,7:]\n",
    "#print(meta_df.head)\n",
    "\n",
    "meta_df['PROBS'] = np.nan\n",
    "meta_df['PREDICTED'] = np.nan\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', C = 1.0)\n",
    "\n",
    "for this_index in df_final.index.tolist():\n",
    "    title = meta_df.loc[meta_df.index[this_index], 'title'] \n",
    "    CLASS = meta_df.loc[meta_df.index[this_index], 'CLASS']\n",
    "    print(title)\n",
    "    train_index_list = [index_ for index_ in feat_df.index.tolist() if index_ != this_index]\n",
    "\n",
    "    X = feat_df.loc[train_index_list]\n",
    "    y = meta_df.loc[train_index_list, 'CLASS']\n",
    "    TEST_CASE = feat_df.loc[[this_index]]\n",
    "\n",
    "    model.fit(X,y)\n",
    "    prediction = model.predict_proba(TEST_CASE)\n",
    "    predicted = model.predict(TEST_CASE)\n",
    "\n",
    "    meta_df.loc[meta_df.index[this_index], 'PREDICTED'] = predicted\n",
    "    meta_df.loc[meta_df.index[this_index], 'PROBS'] = str(prediction)\n",
    "    print('Class is: ' + str(CLASS) + ' ' + 'prediction is: ' + str(predicted) + ' ' + str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "meta2.to_csv('/media/secure_volume/CLASSIFIER_OUTPUT_MASS_TRADE_1980_2007_5.csv', sep='\\t')\n",
    "\n",
    "\n",
    "canonic_c = 1.0\n",
    "\n",
    "\n",
    "def Ztest(vec1, vec2):\n",
    "\n",
    "    X1, X2 = np.mean(vec1), np.mean(vec2)\n",
    "    sd1, sd2 = np.std(vec1), np.std(vec2)\n",
    "    n1, n2 = len(vec1), len(vec2)\n",
    "\n",
    "    pooledSE = np.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = (X1 - X2)/pooledSE\n",
    "    pval = 2*(norm.sf(abs(z)))\n",
    "\n",
    "    return z, pval\n",
    "\n",
    "def feat_pval_weight(meta_df_, dtm_df_):\n",
    "    \n",
    "    #dtm_df_ = dtm_df_.loc[meta_df_.index.tolist()]\n",
    "    dtm_df_ = normalize_model(dtm_df_, dtm_df_)[0]\n",
    "    #dtm_df_ = dtm_df_.dropna(axis = 1, how='any')\n",
    "\n",
    "    dtm0 = dtm_df_.loc[meta_df_[meta_df_['CLASS']==0].index.tolist()].to_numpy()\n",
    "    dtm1 = dtm_df_.loc[meta_df_[meta_df_['CLASS']==1].index.tolist()].to_numpy()\n",
    "\n",
    "    print(dtm0.shape)\n",
    "    print(dtm1.shape)\n",
    "    pvals = [Ztest(dtm0[ : ,i], dtm1[ : ,i])[1] for i in range(dtm_df_.shape[1])]\n",
    "    clf = LogisticRegression(penalty = 'l1', C = canonic_c, class_weight = 'balanced')\n",
    "    clf.fit(dtm_df_, meta_df_['CLASS']==0)\n",
    "    weights = clf.coef_[0]\n",
    "\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    feature_df['FEAT'] = dtm_df_.columns\n",
    "    feature_df['P_VALUE'] = pvals\n",
    "    feature_df['LR_WEIGHT'] = weights\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "#meta_df2 = df_final2.iloc[:,:7]\n",
    "#feat_df2 = df_final2.iloc[:,7:]\n",
    "sig_thresh = 0.05 / len(df2.columns)\n",
    "\n",
    "feat_df = feat_pval_weight(meta2, df2)\n",
    "print(feat_df.shape)\n",
    "\n",
    "feat_df.to_csv('/media/secure_volume/FEATURES_MASS_TRADE_1980_2007_5.csv')\n",
    "out = feat_df[(feat_df['P_VALUE'] <= sig_thresh)].sort_values('LR_WEIGHT', ascending = True)\n",
    "out1 = out['FEAT'].tolist()\n",
    "for o in out1[0:30]:\n",
    "    print(o)\n",
    "featuresFile = open('/media/secure_volume/FEATURE_LIST_MASS_TRADE_1980_2007_5.txt', 'w')\n",
    "out1 = '\\n'.join(out1) \n",
    "featuresFile.write(str(out1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
