{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification, a method popular in machine learning, determines whether and how a model can distinguish between sets of text.\n",
    "\n",
    "It works like this. Everyone with email relies on classification to separate spam from legitimate emails. Email providers train classification models to recognize the difference by giving them emails they have labeled “spam” and “not spam.” They then ask the model to learn the features that most reliably distinguish the two types, which could include a preponderance of all caps or phrases like “free money” or “get paid.” They test the model by giving it unlabeled emails and asking it to classify them. If the model can do it accurately a high percentage of the time, that’s a good spam filter.\n",
    "\n",
    "We can take the underlying idea and apply it to many experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use our _New York Times_ obituaries corpus to test whether our model can learn to distinguish between obituaries about men and women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "As always, we begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from pandas import DataFrame\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import pearsonr, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we'll return to our corpus of _New York Times_ obituaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect filepaths as files\n",
    "directory = \"../docs/NYT-Obituaries/\"\n",
    "files = glob.glob(f\"{directory}/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1945-Adolf-Hitler',\n",
       " '1915-F-W-Taylor',\n",
       " '1975-Chiang-Kai-shek',\n",
       " '1984-Ethel-Merman',\n",
       " '1953-Jim-Thorpe',\n",
       " '1964-Nella-Larsen',\n",
       " '1955-Margaret-Abbott',\n",
       " '1984-Lillian-Hellman',\n",
       " '1959-Cecil-De-Mille',\n",
       " '1928-Mabel-Craty',\n",
       " '1973-Eddie-Rickenbacker',\n",
       " '1989-Ferdinand-Marcos',\n",
       " '1991-Martha-Graham',\n",
       " '1997-Deng-Xiaoping',\n",
       " '1938-George-E-Hale',\n",
       " '1885-Ulysses-Grant',\n",
       " '1909-Sarah-Orne-Jewett',\n",
       " '1957-Christian-Dior',\n",
       " '1987-Clare-Boothe-Luce',\n",
       " '1976-Jacques-Monod',\n",
       " '1954-Getulio-Vargas',\n",
       " '1979-Stan-Kenton',\n",
       " '1990-Leonard-Bernstein',\n",
       " '1972-Jackie-Robinson',\n",
       " '1998-Fred-W-Friendly',\n",
       " '1991-Leo-Durocher',\n",
       " '1915-B-T-Washington',\n",
       " '1997-James-Stewart',\n",
       " '1981-Joe-Louis',\n",
       " '1983-Muddy-Waters',\n",
       " '1942-George-M-Cohan',\n",
       " '1989-Samuel-Beckett',\n",
       " '1962-Marilyn-Monroe',\n",
       " '2000-Charles-M-Schulz',\n",
       " '1967-Gregory-Pincus',\n",
       " '1894-R-L-Stevenson',\n",
       " '1978-Bruce-Catton',\n",
       " '1982-Arthur-Rubinstein',\n",
       " '1875-Andrew-Johnson',\n",
       " '1974-Charles-Lindbergh',\n",
       " '1964-Rachel-Carson',\n",
       " '1953-Marjorie-Rawlings',\n",
       " '1973-Otto-Klemperer',\n",
       " '1963-Sylvia-Plath',\n",
       " '1956-Charles-Merrill',\n",
       " '1966-Lenny-Bruce',\n",
       " '1908-Cleveland',\n",
       " '1982-Anna-Freud',\n",
       " '1941-Frank-Conrad',\n",
       " '1966-Alfred-P-Sloan-Jr',\n",
       " '1960-Beno-Gutenberg',\n",
       " '1976-J-Paul-Getty',\n",
       " '1891-P-T-Barnum',\n",
       " '1901-Queen-Victoria',\n",
       " '1970-Erich-Maria-Remarque',\n",
       " '1989-August-A-Busch-Jr',\n",
       " '1992-John-Cage',\n",
       " '1994-Erik-Erikson',\n",
       " '1990-Erte',\n",
       " '1966-Chester-Nimitz',\n",
       " '1954-Enrico-Fermi',\n",
       " '1961-Primitive-Artist',\n",
       " '1945-Bela-Bartok',\n",
       " '1978-Pope-Paul-VI',\n",
       " '1965-Martin-Buber',\n",
       " '1971-Diane-Arbus',\n",
       " '1973-Lyndon-Johnson',\n",
       " '1998-Bob-Kane',\n",
       " '1969-Judy-Garland',\n",
       " '1959-Frank-Lloyd-Wright',\n",
       " '1995-Ginger-Rogers',\n",
       " '1920-Marlene-Dietrich',\n",
       " '1998-Alan-B-Shepard-Jr',\n",
       " '1971-Khrushchev',\n",
       " '1935-Justice-Holmes',\n",
       " '1969-David-Eisenhower',\n",
       " '1992-Marsha-P-Johnson',\n",
       " '1914-Alfred-Thayer-Mahan',\n",
       " '1965-Branch-Rickey',\n",
       " '1965-Albert-Schweitzer',\n",
       " '1992-Isaac-Asimov',\n",
       " '1989-William-B-Shockley',\n",
       " '1910-William-James',\n",
       " '1951-Fanny-Brice',\n",
       " '1916-Jack-London',\n",
       " '1947-Al-Capone',\n",
       " '1989-Lucille-Ball',\n",
       " '1980-Jean-Paul-Sartre',\n",
       " '1969-Sonja-Henie',\n",
       " '1976-Adolph-Zukor',\n",
       " '1959-John-Dulles',\n",
       " '1980-Alfred-Hitchcock',\n",
       " '1901-Benjamin-Harrison',\n",
       " '1994-Richard-Nixon',\n",
       " '1917-Hilaire-G-E-Degas',\n",
       " '1987-James-Baldwin',\n",
       " '1941-Virginia-Woolf',\n",
       " '1922-Alexander-Graham-Bell',\n",
       " '1907-Qiu-Jin',\n",
       " '1895-Fred-Douglass',\n",
       " '1971-Florence-Blanchfield',\n",
       " '1984-Ray-A-Kroc',\n",
       " '1947-Fiorello-La-Guardia',\n",
       " '1988-Louis-L-Amour',\n",
       " '1902-Elizabeth-Cady-Stanton',\n",
       " '1965-Shirley-Jackson',\n",
       " '1979-John-Wayne',\n",
       " '1994-Thomas-P-O-Neill-Jr',\n",
       " '1982-Thelonious-Monk',\n",
       " '1919-C-J-Walker',\n",
       " '1954-Liberty-H-Bailey',\n",
       " '1977-Dash-Ended',\n",
       " '1936-Maxim-Gorky',\n",
       " '2000-Pierre-Trudeau',\n",
       " '1976-Mao-Tse-Tung',\n",
       " '1955-Walter-White',\n",
       " '1930-Conan-Doyle',\n",
       " '1995-Jonas-Salk',\n",
       " '1949-Mitchell',\n",
       " '1951-Henrietta-Lacks',\n",
       " '1903-James-M-N-Whistler',\n",
       " '1950-A-J-Dempster',\n",
       " '1937-Edith-Wharton',\n",
       " '1935-Jane-Addams',\n",
       " '1941-James-Joyce',\n",
       " '1952-John-Dewey',\n",
       " '1940-Marcus-Garvey',\n",
       " '1971-Louis-Armstrong',\n",
       " '1923-Warren-Harding',\n",
       " '1937-John-Rockefeller',\n",
       " '2000-Elliot-Richardson',\n",
       " '1972-J-Edgar-Hoover',\n",
       " '1975-Franco',\n",
       " '1973-Jeanette-Rankin',\n",
       " '1888-Louisa-M-Alcott',\n",
       " '1977-Charles-Chaplin',\n",
       " '1990-Ralph-David-Abernathy',\n",
       " '1946-Lord-Keynes',\n",
       " '1996-Gene-Kelly',\n",
       " '1973-Roberto-Clemente',\n",
       " '1986-Georgia-O-Keeffe',\n",
       " '1990-Rex-Harrison',\n",
       " '1916-Martian-Theory',\n",
       " '1961-Ernest-Hemingway',\n",
       " '1978-Margaret-Mead',\n",
       " '1982-Ingrid-Bergman',\n",
       " '1946-C-E-M-Clung',\n",
       " '1977-Maria-Callas',\n",
       " '1952-Eva-Peron',\n",
       " '1961-Emily-Balch',\n",
       " '1979-Arthur-Fiedler',\n",
       " '1896-Harriet-Beecher-Stowe',\n",
       " '1989-Andrei-Sakharov',\n",
       " '1939-W-B-Yeats',\n",
       " '1961-Hammarskjold',\n",
       " '1969-Madhubala',\n",
       " '1970-Edouard-Daladier',\n",
       " '1988-John-Houseman',\n",
       " '1992-William-Shawn',\n",
       " '1950-Edna-St-V-Millay',\n",
       " '1989-Claude-Pepper',\n",
       " '1929-Marie-Curie',\n",
       " '1972-The-Duke-of-Windsor',\n",
       " '1984-Count-Basie',\n",
       " '1998-Helen-Moody',\n",
       " '1936-Anne-Macy',\n",
       " '1900-Nietzsche',\n",
       " '1880-Lucretia-Mott',\n",
       " '1967-J-Robert-Oppenheimer',\n",
       " '1984-Richard-Burton',\n",
       " '1964-Sean-O-Casey',\n",
       " '1931-Thomas-Edison',\n",
       " '1971-Bobby-Jones',\n",
       " '1914-John-P-Holland',\n",
       " '1995-George-Abbott',\n",
       " '1950-Henry-L-Stimson',\n",
       " '1955-Dale-Carnegie',\n",
       " '1934-T-A-Watson',\n",
       " '1968-Martin-Luther-King-Jr',\n",
       " '1933-Louis-C-Tiffany',\n",
       " '1909-Geronimo',\n",
       " '1952-Charles-Spaulding',\n",
       " '1922-Nellie-Bly',\n",
       " '1955-Cy-Young',\n",
       " '1993-Arthur-Ashe',\n",
       " '1986-Bernard-Malamud',\n",
       " '1939-Howard-Carter',\n",
       " '1994-Linus-C-Pauling',\n",
       " '1967-Langston-Hughes',\n",
       " '1948-Mohandas-K-Gandhi',\n",
       " '1931-Melvil-Dewey',\n",
       " '1969-Everett-Dirksen',\n",
       " '1968-Helen-Keller',\n",
       " '1992-Alex-Haley',\n",
       " '1953-Eugene-O-Neill',\n",
       " '1981-Anwar-el-Sadat',\n",
       " '1937-Maurice-Ravel',\n",
       " '1966-Margaret-Sanger',\n",
       " '1989-I-F-Stone',\n",
       " '1943-J-H-Kellogg',\n",
       " '1985-Roger-Maris',\n",
       " '1972-Mahalia-Jackson',\n",
       " '1990-Greta-Garbo',\n",
       " '1998-Benjamin-Spock',\n",
       " '1994-Jessica-Tandy',\n",
       " '1979-Richard-Rodgers',\n",
       " '1958-W-C-Handy',\n",
       " '1974-Ed-Sullivan',\n",
       " '1989-Hirohito',\n",
       " '1933-Calvin-Coolidge',\n",
       " '1969-Ho-Chi-Minh',\n",
       " '1987-John-Huston',\n",
       " '1984-Johnny-Weissmuller',\n",
       " '1969-Maureen-Connolly',\n",
       " '1968-Yuri-Gagarin',\n",
       " '1991-Peggy-Ashcroft',\n",
       " '1979-A-Philip-Randolph',\n",
       " '1946-Gertrude-Stein',\n",
       " '1993-Thurgood-Marshall',\n",
       " '1887-Emma-Lazarus',\n",
       " '1986-James-Cagney',\n",
       " '1976-Richard-Daley',\n",
       " '1977-Joan-Crawford',\n",
       " '1971-Hugo-Black',\n",
       " '1954-Henri-Matisse',\n",
       " '1906-Susan-B-Anthony',\n",
       " '1990-Sammy-Davis-Jr',\n",
       " '1914-John-Muir',\n",
       " '1954-Anne-O-Hare-McCormick',\n",
       " '1986-Kate-Smith',\n",
       " '1919-Anna-H-Shaw',\n",
       " '1980-Jean-Piaget',\n",
       " '1966-Buster-Keaton',\n",
       " '1997-Allen-Ginsberg',\n",
       " '1991-Miles-Davis',\n",
       " '1982-Satchel-Paige',\n",
       " '1931-Ida-B-Wells',\n",
       " '1967-Henry-R-Luce',\n",
       " '1984-Ansel-Adams',\n",
       " '1945-Ernie-Pyle',\n",
       " '1952-Chaim-Weizmann',\n",
       " '1973-Nancy-Mitford',\n",
       " '1852-Ada-Lovelace',\n",
       " '1996-Timothy-Leary',\n",
       " '1919-Carnegie-Started',\n",
       " '1989-Andrei-A-Gromyko',\n",
       " '1965-David-O-Selznick',\n",
       " '1870-Robert-E-Lee',\n",
       " '1968-Robert-Francis-Kennedy',\n",
       " '1900-Stephen-Crane',\n",
       " '1936-John-W-Heisman',\n",
       " '1998-Maureen-O-Sullivan',\n",
       " '1953-Joseph-Stalin',\n",
       " '1944-Alfred-E-Smith',\n",
       " '1910-Tolstoy',\n",
       " '1964-Cole-Porter',\n",
       " '1983-Jack-Dempsey',\n",
       " '1975-Haile-Selassie',\n",
       " '1882-Charles-Darwin',\n",
       " '1903-Emily-Warren-Roebling',\n",
       " '1962-Eleanor-Roosevelt',\n",
       " '1926-Harry-Houdini',\n",
       " '1955-Albert-Einstein',\n",
       " '1971-Coco-Chanel',\n",
       " '1959-Billie-Holiday',\n",
       " '1969-Coleman-Hawkins',\n",
       " '1954-Frida-Kahlo',\n",
       " '1911-Joseph-Pulitzer',\n",
       " '1993-Carlos-Montoya',\n",
       " '1947-Max-Planck',\n",
       " '1985-Orson-Welles',\n",
       " '1974-Earl-Warren',\n",
       " '1971-Ralph-Bunche',\n",
       " '1999-Hassan-II',\n",
       " '1931-Knute-Rocke',\n",
       " '1998-Theodore-Schultz',\n",
       " '1960-Boris-Pasternak',\n",
       " '1927-Victoria-Martin',\n",
       " '1943-George-Washington-Carver',\n",
       " '1956-Thomas-J-Watson-Sr',\n",
       " '1947-Henry-Ford',\n",
       " '1953-Fred-Vinson',\n",
       " '1982-Leonid-Brezhnev',\n",
       " '1999-King-Hussein',\n",
       " '1930-Elmer-Sperry',\n",
       " '1985-E-B-White',\n",
       " '1959-Ethel-Barrymore',\n",
       " '1986-Benny-Goodman',\n",
       " '1963-W-E-B-DuBois',\n",
       " '1975-Elijah-Muhammad',\n",
       " '1973-Pablo-Picasso',\n",
       " '1993-Federico-Fellini',\n",
       " '1945-Harry-S-Truman',\n",
       " '1970-De-Gaulle-Rallied',\n",
       " '1995-Alfred-Eisenstaedt',\n",
       " '1999-Iris-Murdoch',\n",
       " '1987-Alf-Landon',\n",
       " '1998-Bella-Abzug',\n",
       " '1940-Scott-Fitzgerald',\n",
       " '1989-Vladimir-Horowitz',\n",
       " '1969-Mies-van-der-Rohe',\n",
       " '1944-Ida-M-Tarbell',\n",
       " '1948-John-Pershing',\n",
       " '1938-Clarence-Darrow',\n",
       " '1987-Primo-Levi',\n",
       " '1971-Igor-Stravinsky',\n",
       " '1945-George-Patton',\n",
       " '1930-William-Howard-Taft',\n",
       " '1935-Will-Rogers',\n",
       " '1992-Shirley-Booth',\n",
       " '1994-Jacqueline-Kennedy',\n",
       " '1933-Ring-Lardner',\n",
       " '1974-Sylvia-Plath',\n",
       " '1945-FDR',\n",
       " '1995-Yitzhak-Rabin',\n",
       " '1960-Emily-Post',\n",
       " '1984-Truman-Capote',\n",
       " '1968-Upton-Sinclair',\n",
       " '1994-Jan-Tinbergen',\n",
       " '1957-Gerard-Swope',\n",
       " '1993-Albert-Sabin',\n",
       " '1955-Thomas-Mann',\n",
       " '1991-Dr-Seuss',\n",
       " '1877-Bedford-Forrest',\n",
       " '1964-Douglas-MacArthur',\n",
       " '1965-Churchill',\n",
       " '1962-William-Faulkner',\n",
       " '1956-Babe-Zaharias',\n",
       " '1932-John-Philip-Sousa',\n",
       " '1964-Herbert-Hoover',\n",
       " '1961-Sam-Rayburn',\n",
       " '1954-Lionel-Barrymore',\n",
       " '1998-Frank-Sinatra',\n",
       " '1948-Babe-Ruth',\n",
       " '1947-Willa-Cather',\n",
       " '1963-John-F-Kennedy',\n",
       " '1975-Walker-Evans',\n",
       " '1916-J-J-Hill',\n",
       " '1980-Jesse-Owens',\n",
       " '1948-Sergei-Eisenstein',\n",
       " '1981-Robert-Moses',\n",
       " '1989-Robert-Penn-Warren',\n",
       " '1901-William-McKinley',\n",
       " '1970-Walter-Reuther',\n",
       " '1930-Balfour',\n",
       " '1984-Indira-Gandhi',\n",
       " '1978-Golda-Meir',\n",
       " '1983-Earl-Hines',\n",
       " '1974-Katharine-Cornell',\n",
       " '1982-Lee-Strasberg',\n",
       " '1939-Pope-Pius-XI',\n",
       " '1886-Mary-Ewing-Outerbridge',\n",
       " '1993-Dizzy-Gillespie',\n",
       " '1910-Florence-Nightingale',\n",
       " '1960-Richard-Wright',\n",
       " '1986-The-Challenger',\n",
       " '1992-Menachem-Begin',\n",
       " '1998-Galina-Ulanova',\n",
       " '1976-Max-Ernst',\n",
       " '1993-Cesar-Chavez',\n",
       " '1965-Adlai-Ewing-Stevenson',\n",
       " '1935-Adolph-S-Ochs',\n",
       " '1941-Lou-Gehrig',\n",
       " '1961-Carl-G-Jung',\n",
       " '1963-Robert-Frost',\n",
       " '1965-Edward-R-Murrow',\n",
       " '1971-Dean-Acheson',\n",
       " '1986-Jorge-Luis-Borges',\n",
       " '1966-Walt-Disney',\n",
       " '1996-Carl-Sagan',\n",
       " '1959-Ross-G-Harrison',\n",
       " '1945-Jerome-Kern',\n",
       " '1991-Frank-Capra',\n",
       " '1987-Andres-Segovie',\n",
       " '1987-Rita-Hayworth',\n",
       " '1993-William-Golding',\n",
       " '1932-Florenz-Ziegfeld',\n",
       " '1938-Constantin-Stanislavsky']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and collect obit titles, which are also the final section of the filepaths\n",
    "obit_titles = [Path(file).stem for file in files]\n",
    "obit_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate CountVectorizer as vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember document-term matrices, aka doc-term matrices, aka dtms? We learned about them in notebooks 10 and 11. Our classifier uses a dtm as its input. We build it with scikit-learn's CountVectorizer, which we imported at the start of the lesson. \n",
    "\n",
    "When we load our vectorizer, we include an argument to encode as utf-8 and we load our stopwords. We can also set the minimum number of times a word must appear in the corpus to be included in the dtm. In this case, I've set it at 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "text_file = open('../docs/jockers_stopwords.txt')\n",
    "jockers_words = text_file.read().split()\n",
    "new_stopwords = text.ENGLISH_STOP_WORDS.union(jockers_words)\n",
    "\n",
    "# create dtm\n",
    "corpus_path = '../docs/NYT-Obituaries/'\n",
    "vectorizer = CountVectorizer(input='filename', encoding='utf8', stop_words = new_stopwords, min_df=20, dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make list of filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer builds a dtm from a list of filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for title in obit_titles:\n",
    "    filename = title + \".txt\"\n",
    "    corpus.append(corpus_path + filename)\n",
    "dtm = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature names and set as column titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns store word counts. We want to name the columns with the words stored in each, and to transform the dtm into a pandas dataframe, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape is: (378, 2985)\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "matrix = dtm.toarray()\n",
    "df = DataFrame(matrix, columns=vocab)\n",
    "print('df shape is: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframee has 378 rows, one for each document, or obituary, and 2985 columns, one for each word that's not in stopwords and appears at least 20 times in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1945-Adolf-Hitler</td>\n",
       "      <td>0</td>\n",
       "      <td>1945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1915-F-W-Taylor</td>\n",
       "      <td>0</td>\n",
       "      <td>1915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1975-Chiang-Kai-shek</td>\n",
       "      <td>0</td>\n",
       "      <td>1975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1984-Ethel-Merman</td>\n",
       "      <td>1</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1953-Jim-Thorpe</td>\n",
       "      <td>0</td>\n",
       "      <td>1953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>1987-Andres-Segovie</td>\n",
       "      <td>0</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1993-William-Golding</td>\n",
       "      <td>0</td>\n",
       "      <td>1993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>1938-Constantin-Stanislavsky</td>\n",
       "      <td>0</td>\n",
       "      <td>1938.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       obit_title  gender    date\n",
       "0               1945-Adolf-Hitler       0  1945.0\n",
       "1                 1915-F-W-Taylor       0  1915.0\n",
       "2            1975-Chiang-Kai-shek       0  1975.0\n",
       "3               1984-Ethel-Merman       1  1984.0\n",
       "4                 1953-Jim-Thorpe       0  1953.0\n",
       "..                            ...     ...     ...\n",
       "373           1987-Andres-Segovie       0  1987.0\n",
       "374            1987-Rita-Hayworth       1  1987.0\n",
       "375          1993-William-Golding       0  1993.0\n",
       "376         1932-Florenz-Ziegfeld       1  1932.0\n",
       "377  1938-Constantin-Stanislavsky       0  1938.0\n",
       "\n",
       "[378 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(\"../docs/NYT-Obituaries.csv\", encoding = 'utf-8')\n",
    "meta = meta.rename(columns={'title': 'obit_title'})\n",
    "meta = meta[[\"obit_title\", \"gender\", \"date\"]]\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our metadata is stored as a pandas dataframe with a row for each obituary and three columns: title, gender, and year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate metadata and doc-term dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([meta, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yale</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1945-Adolf-Hitler</td>\n",
       "      <td>0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1915-F-W-Taylor</td>\n",
       "      <td>0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1975-Chiang-Kai-shek</td>\n",
       "      <td>0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1984-Ethel-Merman</td>\n",
       "      <td>1</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1953-Jim-Thorpe</td>\n",
       "      <td>0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             obit_title  gender    date   000   10  100   11   12   13   14  \\\n",
       "0     1945-Adolf-Hitler       0  1945.0  21.0  1.0  0.0  2.0  3.0  4.0  3.0   \n",
       "1       1915-F-W-Taylor       0  1915.0   0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2  1975-Chiang-Kai-shek       0  1975.0   3.0  3.0  1.0  1.0  0.0  0.0  0.0   \n",
       "3     1984-Ethel-Merman       1  1984.0   0.0  1.0  0.0  1.0  0.0  1.0  2.0   \n",
       "4       1953-Jim-Thorpe       0  1953.0   2.0  3.0  1.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "   ...  wrote  yale  year  years  yellow  yesterday  york  younger  youngest  \\\n",
       "0  ...    3.0   0.0  11.0   19.0     0.0        0.0   1.0      1.0       0.0   \n",
       "1  ...    0.0   0.0   0.0    1.0     0.0        0.0   1.0      0.0       0.0   \n",
       "2  ...    6.0   0.0   3.0   14.0     0.0        0.0   1.0      2.0       1.0   \n",
       "3  ...    0.0   0.0   3.0    5.0     0.0        2.0   5.0      0.0       0.0   \n",
       "4  ...    0.0   0.0   6.0    1.0     0.0        0.0   4.0      0.0       0.0   \n",
       "\n",
       "   youth  \n",
       "0    9.0  \n",
       "1    0.0  \n",
       "2    1.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 2988 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalize numbers of men and women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our dataframe to have equal numbers of men and women. How many women are there? Women are counted as 1 and men as 0, so if we sum the gender column, we'll have the number of women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['gender'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate men and women into two dataframes and take a random sample of 93 obituaries about men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_men = df_concat[df_concat['gender'] == 0]\n",
    "df_women = df_concat[df_concat['gender'] == 1]\n",
    "df_men = df_men.sample(n=93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then concatenate the sampled men dataframe with the women dataframe and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yale</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1936-John-W-Heisman</td>\n",
       "      <td>0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1971-Dean-Acheson</td>\n",
       "      <td>0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1970-Edouard-Daladier</td>\n",
       "      <td>0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1995-Jonas-Salk</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1988-John-Houseman</td>\n",
       "      <td>0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1910-Florence-Nightingale</td>\n",
       "      <td>1</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1986-The-Challenger</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1998-Galina-Ulanova</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 2988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    obit_title  gender    date  000   10  100   11   12   13  \\\n",
       "0          1936-John-W-Heisman       0  1936.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1            1971-Dean-Acheson       0  1971.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2        1970-Edouard-Daladier       0  1946.0  0.0  0.0  0.0  2.0  1.0  0.0   \n",
       "3              1995-Jonas-Salk       0  1995.0  4.0  0.0  1.0  0.0  1.0  0.0   \n",
       "4           1988-John-Houseman       0  1988.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "..                         ...     ...     ...  ...  ...  ...  ...  ...  ...   \n",
       "181  1910-Florence-Nightingale       1  1854.0  3.0  0.0  0.0  0.0  1.0  0.0   \n",
       "182        1986-The-Challenger       1  1986.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "183        1998-Galina-Ulanova       1  1998.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "184         1987-Rita-Hayworth       1  1987.0  0.0  2.0  0.0  0.0  1.0  0.0   \n",
       "185      1932-Florenz-Ziegfeld       1  1932.0  9.0  3.0  1.0  1.0  0.0  0.0   \n",
       "\n",
       "      14  ...  wrote  yale  year  years  yellow  yesterday  york  younger  \\\n",
       "0    0.0  ...    0.0   0.0   2.0    3.0     0.0        1.0   1.0      0.0   \n",
       "1    0.0  ...    7.0   2.0   1.0    8.0     0.0        0.0   1.0      0.0   \n",
       "2    0.0  ...    0.0   0.0   1.0    3.0     0.0        1.0   1.0      0.0   \n",
       "3    0.0  ...    0.0   0.0   7.0    5.0     0.0        1.0   3.0      1.0   \n",
       "4    0.0  ...    5.0   0.0   1.0    7.0     0.0        1.0   4.0      0.0   \n",
       "..   ...  ...    ...   ...   ...    ...     ...        ...   ...      ...   \n",
       "181  1.0  ...    2.0   0.0   2.0    7.0     0.0        1.0   1.0      0.0   \n",
       "182  0.0  ...    1.0   0.0   4.0    1.0     0.0        0.0   1.0      0.0   \n",
       "183  0.0  ...    5.0   0.0   1.0    1.0     0.0        0.0   4.0      0.0   \n",
       "184  0.0  ...    0.0   0.0   1.0    8.0     0.0        1.0   2.0      0.0   \n",
       "185  0.0  ...    0.0   0.0   4.0    6.0     0.0        0.0   2.0      2.0   \n",
       "\n",
       "     youngest  youth  \n",
       "0         0.0    0.0  \n",
       "1         0.0    0.0  \n",
       "2         0.0    0.0  \n",
       "3         0.0    0.0  \n",
       "4         1.0    0.0  \n",
       "..        ...    ...  \n",
       "181       0.0    1.0  \n",
       "182       0.0    1.0  \n",
       "183       0.0    0.0  \n",
       "184       0.0    0.0  \n",
       "185       0.0    0.0  \n",
       "\n",
       "[186 rows x 2988 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_men, df_women])\n",
    "df_final = df_final.reset_index()\n",
    "df_final = df_final.drop(columns=\"index\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 186 rows: 93 men, 93 women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match meta and data dataframes with subset of df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue to use meta and df, so we need to ensure they match our subsetted df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1936-John-W-Heisman</td>\n",
       "      <td>0</td>\n",
       "      <td>1936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1971-Dean-Acheson</td>\n",
       "      <td>0</td>\n",
       "      <td>1971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1970-Edouard-Daladier</td>\n",
       "      <td>0</td>\n",
       "      <td>1946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1995-Jonas-Salk</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1988-John-Houseman</td>\n",
       "      <td>0</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1910-Florence-Nightingale</td>\n",
       "      <td>1</td>\n",
       "      <td>1854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1986-The-Challenger</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1998-Galina-Ulanova</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    obit_title  gender    date\n",
       "0          1936-John-W-Heisman       0  1936.0\n",
       "1            1971-Dean-Acheson       0  1971.0\n",
       "2        1970-Edouard-Daladier       0  1946.0\n",
       "3              1995-Jonas-Salk       0  1995.0\n",
       "4           1988-John-Houseman       0  1988.0\n",
       "..                         ...     ...     ...\n",
       "181  1910-Florence-Nightingale       1  1854.0\n",
       "182        1986-The-Challenger       1  1986.0\n",
       "183        1998-Galina-Ulanova       1  1998.0\n",
       "184         1987-Rita-Hayworth       1  1987.0\n",
       "185      1932-Florenz-Ziegfeld       1  1932.0\n",
       "\n",
       "[186 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = df_final[[\"obit_title\", \"gender\", \"date\"]]\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yale</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 2985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000   10  100   11   12   13   14   15  150   16  ...  wrote  yale  year  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   2.0   \n",
       "1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...    7.0   2.0   1.0   \n",
       "2    0.0  0.0  0.0  2.0  1.0  0.0  0.0  1.0  0.0  0.0  ...    0.0   0.0   1.0   \n",
       "3    4.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   7.0   \n",
       "4    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    5.0   0.0   1.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   ...   ...   \n",
       "181  3.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  ...    2.0   0.0   2.0   \n",
       "182  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    1.0   0.0   4.0   \n",
       "183  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    5.0   0.0   1.0   \n",
       "184  0.0  2.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  2.0  ...    0.0   0.0   1.0   \n",
       "185  9.0  3.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   4.0   \n",
       "\n",
       "     years  yellow  yesterday  york  younger  youngest  youth  \n",
       "0      3.0     0.0        1.0   1.0      0.0       0.0    0.0  \n",
       "1      8.0     0.0        0.0   1.0      0.0       0.0    0.0  \n",
       "2      3.0     0.0        1.0   1.0      0.0       0.0    0.0  \n",
       "3      5.0     0.0        1.0   3.0      1.0       0.0    0.0  \n",
       "4      7.0     0.0        1.0   4.0      0.0       1.0    0.0  \n",
       "..     ...     ...        ...   ...      ...       ...    ...  \n",
       "181    7.0     0.0        1.0   1.0      0.0       0.0    1.0  \n",
       "182    1.0     0.0        0.0   1.0      0.0       0.0    1.0  \n",
       "183    1.0     0.0        0.0   4.0      0.0       0.0    0.0  \n",
       "184    8.0     0.0        1.0   2.0      0.0       0.0    0.0  \n",
       "185    6.0     0.0        0.0   2.0      2.0       0.0    0.0  \n",
       "\n",
       "[186 rows x 2985 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_final.loc[:,'000':]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a dataframe with metadata and vocab counts we're ready to run our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We add columns for probabilities and predicted class to our metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we run the model, we are going to store its output with our metadata. This will allow us to easily examine the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "meta['PROBS'] = ''\n",
    "meta['PREDICTED'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use scikit-learn's `LogisticRegression` model. There are many other options for classifier models. Some are better for some tasks, other for others. LogisticRegression is standard for classifying literature. We set the penalty as l1 and the 'C' value as 1.0. If you decide to specialize in classification, you can explore further the implications of these arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty = 'l1', C = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the model in the following for-loop.\n",
    "\n",
    "Classification models need classes: they need the texts grouped into different sets. Our metadata has built-in classes: gender. Men are stored as 0; women as 1. We could, if we wanted, create a new 0/1 class based on year.\n",
    "\n",
    "Each iteration trains on all the titles except one, then predicts which class the excluded title belongs to. We'll call this leave-one-out classification. There are other ways of dividing training and testing sets, which we won't explore today.\n",
    "\n",
    "The first four indented lines simply track our progress by printing index, title, and class. The next four lines exclude a single title, and set the training data and the test data.\n",
    "\n",
    "The final six lines fit the model, calculate the probabilities and predicted class of the test case, and add that information to our metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1936-John-W-Heisman 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.79355842 0.20644158]]\n",
      "\n",
      "1\n",
      "1971-Dean-Acheson 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999779e-01 2.21229604e-07]]\n",
      "\n",
      "2\n",
      "1970-Edouard-Daladier 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.98035948 0.01964052]]\n",
      "\n",
      "3\n",
      "1995-Jonas-Salk 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99988000e-01 1.19995998e-05]]\n",
      "\n",
      "4\n",
      "1988-John-Houseman 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.39230848 0.60769152]]\n",
      "\n",
      "5\n",
      "1968-Yuri-Gagarin 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.80787114 0.19212886]]\n",
      "\n",
      "6\n",
      "1957-Gerard-Swope 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.98994386 0.01005614]]\n",
      "\n",
      "7\n",
      "1994-Linus-C-Pauling 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99996248e-01 3.75212485e-06]]\n",
      "\n",
      "8\n",
      "1985-Orson-Welles 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.93995894 0.06004106]]\n",
      "\n",
      "9\n",
      "1984-Count-Basie 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.94674981 0.05325019]]\n",
      "\n",
      "10\n",
      "1943-J-H-Kellogg 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.67547514 0.32452486]]\n",
      "\n",
      "11\n",
      "1992-Alex-Haley 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.3289677 0.6710323]]\n",
      "\n",
      "12\n",
      "1931-Melvil-Dewey 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.96238521 0.03761479]]\n",
      "\n",
      "13\n",
      "1967-J-Robert-Oppenheimer 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[1.00000000e+00 1.23999369e-11]]\n",
      "\n",
      "14\n",
      "1981-Robert-Moses 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 0\n",
      "Prediction is: [0] [[0.97883526 0.02116474]]\n",
      "\n",
      "15\n",
      "1973-Lyndon-Johnson 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99404996e-01 5.95003619e-04]]\n",
      "\n",
      "16\n",
      "1941-Frank-Conrad 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.96332145 0.03667855]]\n",
      "\n",
      "17\n",
      "1984-Ansel-Adams 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.87330515 0.12669485]]\n",
      "\n",
      "18\n",
      "1990-Ralph-David-Abernathy 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99896178e-01 1.03822097e-04]]\n",
      "\n",
      "19\n",
      "1935-Will-Rogers 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.81817072 0.18182928]]\n",
      "\n",
      "20\n",
      "1994-Jan-Tinbergen 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.8062079 0.1937921]]\n",
      "\n",
      "21\n",
      "1994-Thomas-P-O-Neill-Jr 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99788638e-01 2.11362492e-04]]\n",
      "\n",
      "22\n",
      "1989-Ferdinand-Marcos 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.00812173 0.99187827]]\n",
      "\n",
      "23\n",
      "1910-William-James 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.96898195 0.03101805]]\n",
      "\n",
      "24\n",
      "1937-John-Rockefeller 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.9889836 0.0110164]]\n",
      "\n",
      "25\n",
      "1973-Otto-Klemperer 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.27508426 0.72491574]]\n",
      "\n",
      "26\n",
      "1990-Rex-Harrison 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.55539414 0.44460586]]\n",
      "\n",
      "27\n",
      "1935-Adolph-S-Ochs 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99998479e-01 1.52101771e-06]]\n",
      "\n",
      "28\n",
      "1976-Max-Ernst 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99870833 0.00129167]]\n",
      "\n",
      "29\n",
      "1987-James-Baldwin 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 0\n",
      "Prediction is: [0] [[0.99077256 0.00922744]]\n",
      "\n",
      "30\n",
      "1969-Coleman-Hawkins 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.81938776 0.18061224]]\n",
      "\n",
      "31\n",
      "1945-Adolf-Hitler 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99994629e-01 5.37147531e-06]]\n",
      "\n",
      "32\n",
      "1969-Mies-van-der-Rohe 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99684422 0.00315578]]\n",
      "\n",
      "33\n",
      "1989-Andrei-Sakharov 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999697e-01 3.02605569e-07]]\n",
      "\n",
      "34\n",
      "1965-Churchill 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999918e-01 8.19405231e-08]]\n",
      "\n",
      "35\n",
      "1977-Dash-Ended 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99867667e-01 1.32333120e-04]]\n",
      "\n",
      "36\n",
      "1989-Andrei-A-Gromyko 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99998011e-01 1.98931056e-06]]\n",
      "\n",
      "37\n",
      "1978-Pope-Paul-VI 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.03282008 0.96717992]]\n",
      "\n",
      "38\n",
      "1942-George-M-Cohan 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.98257334 0.01742666]]\n",
      "\n",
      "39\n",
      "1986-Benny-Goodman 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99998627e-01 1.37261716e-06]]\n",
      "\n",
      "40\n",
      "1916-J-J-Hill 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99679591 0.00320409]]\n",
      "\n",
      "41\n",
      "1984-Truman-Capote 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.02536807 0.97463193]]\n",
      "\n",
      "42\n",
      "1968-Robert-Francis-Kennedy 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.98334257 0.01665743]]\n",
      "\n",
      "43\n",
      "1995-Yitzhak-Rabin 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99991020e-01 8.98015744e-06]]\n",
      "\n",
      "44\n",
      "1947-Max-Planck 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 0\n",
      "Prediction is: [0] [[0.98254746 0.01745254]]\n",
      "\n",
      "45\n",
      "1914-John-Muir 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.95648481 0.04351519]]\n",
      "\n",
      "46\n",
      "1875-Andrew-Johnson 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99458369e-01 5.41630857e-04]]\n",
      "\n",
      "47\n",
      "1997-James-Stewart 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99295745 0.00704255]]\n",
      "\n",
      "48\n",
      "1952-Chaim-Weizmann 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99971582e-01 2.84175616e-05]]\n",
      "\n",
      "49\n",
      "1954-Enrico-Fermi 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99743935e-01 2.56065358e-04]]\n",
      "\n",
      "50\n",
      "1939-Pope-Pius-XI 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99965417e-01 3.45833823e-05]]\n",
      "\n",
      "51\n",
      "1935-Justice-Holmes 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.82364084 0.17635916]]\n",
      "\n",
      "52\n",
      "1954-Getulio-Vargas 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99114278 0.00885722]]\n",
      "\n",
      "53\n",
      "1984-Johnny-Weissmuller 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.08180441 0.91819559]]\n",
      "\n",
      "54\n",
      "1993-Albert-Sabin 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99998052e-01 1.94773051e-06]]\n",
      "\n",
      "55\n",
      "1939-W-B-Yeats 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.28880672 0.71119328]]\n",
      "\n",
      "56\n",
      "1947-Henry-Ford 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999861e-01 1.38532224e-07]]\n",
      "\n",
      "57\n",
      "1944-Alfred-E-Smith 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.04797124 0.95202876]]\n",
      "\n",
      "58\n",
      "1971-Khrushchev 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99989141e-01 1.08588114e-05]]\n",
      "\n",
      "59\n",
      "1974-Charles-Lindbergh 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99895444 0.00104556]]\n",
      "\n",
      "60\n",
      "1953-Jim-Thorpe 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99634118 0.00365882]]\n",
      "\n",
      "61\n",
      "1961-Sam-Rayburn 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 0\n",
      "Prediction is: [0] [[9.99988364e-01 1.16364537e-05]]\n",
      "\n",
      "62\n",
      "1945-Ernie-Pyle 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.03144808 0.96855192]]\n",
      "\n",
      "63\n",
      "1938-Constantin-Stanislavsky 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.88579174 0.11420826]]\n",
      "\n",
      "64\n",
      "1967-Gregory-Pincus 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.06895972 0.93104028]]\n",
      "\n",
      "65\n",
      "1978-Bruce-Catton 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.50774572 0.49225428]]\n",
      "\n",
      "66\n",
      "1970-De-Gaulle-Rallied 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999743e-01 2.56568998e-07]]\n",
      "\n",
      "67\n",
      "1967-Henry-R-Luce 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.98893138 0.01106862]]\n",
      "\n",
      "68\n",
      "1986-Jorge-Luis-Borges 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.90518532 0.09481468]]\n",
      "\n",
      "69\n",
      "1926-Harry-Houdini 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.84385102 0.15614898]]\n",
      "\n",
      "70\n",
      "1998-Frank-Sinatra 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.02597769 0.97402231]]\n",
      "\n",
      "71\n",
      "1932-John-Philip-Sousa 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99588225e-01 4.11775384e-04]]\n",
      "\n",
      "72\n",
      "1979-A-Philip-Randolph 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99989730e-01 1.02697857e-05]]\n",
      "\n",
      "73\n",
      "1962-William-Faulkner 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.31381604 0.68618396]]\n",
      "\n",
      "74\n",
      "1909-Geronimo 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.92326054 0.07673946]]\n",
      "\n",
      "75\n",
      "1919-Carnegie-Started 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999914e-01 8.55979347e-08]]\n",
      "\n",
      "76\n",
      "1975-Elijah-Muhammad 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.87523366 0.12476634]]\n",
      "\n",
      "77\n",
      "1877-Bedford-Forrest 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.86685347 0.13314653]]\n",
      "\n",
      "78\n",
      "1959-Cecil-De-Mille 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 0\n",
      "Prediction is: [0] [[0.73784122 0.26215878]]\n",
      "\n",
      "79\n",
      "1980-Jesse-Owens 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.9988516 0.0011484]]\n",
      "\n",
      "80\n",
      "1961-Carl-G-Jung 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99992031e-01 7.96886352e-06]]\n",
      "\n",
      "81\n",
      "1955-Thomas-Mann 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.97563727 0.02436273]]\n",
      "\n",
      "82\n",
      "1986-James-Cagney 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99868581 0.00131419]]\n",
      "\n",
      "83\n",
      "1945-FDR 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99436868 0.00563132]]\n",
      "\n",
      "84\n",
      "1923-Warren-Harding 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[9.99999999e-01 5.24098358e-10]]\n",
      "\n",
      "85\n",
      "1963-Robert-Frost 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.43609737 0.56390263]]\n",
      "\n",
      "86\n",
      "1966-Walt-Disney 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.93470129 0.06529871]]\n",
      "\n",
      "87\n",
      "1954-Henri-Matisse 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.72523268 0.27476732]]\n",
      "\n",
      "88\n",
      "1993-Dizzy-Gillespie 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.99873891 0.00126109]]\n",
      "\n",
      "89\n",
      "1985-Roger-Maris 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.83784886 0.16215114]]\n",
      "\n",
      "90\n",
      "1952-Charles-Spaulding 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.62498558 0.37501442]]\n",
      "\n",
      "91\n",
      "1931-Knute-Rocke 0\n",
      "Class is: 0\n",
      "Prediction is: [0] [[0.65301771 0.34698229]]\n",
      "\n",
      "92\n",
      "1930-Elmer-Sperry 0\n",
      "Class is: 0\n",
      "Prediction is: [1] [[0.33862381 0.66137619]]\n",
      "\n",
      "93\n",
      "1984-Ethel-Merman 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.69328608 0.30671392]]\n",
      "\n",
      "94\n",
      "1964-Nella-Larsen 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 1\n",
      "Prediction is: [1] [[1.35854012e-04 9.99864146e-01]]\n",
      "\n",
      "95\n",
      "1955-Margaret-Abbott 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[6.81516377e-09 9.99999993e-01]]\n",
      "\n",
      "96\n",
      "1984-Lillian-Hellman 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00163692 0.99836308]]\n",
      "\n",
      "97\n",
      "1928-Mabel-Craty 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.25208215 0.74791785]]\n",
      "\n",
      "98\n",
      "1991-Martha-Graham 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.3773696 0.6226304]]\n",
      "\n",
      "99\n",
      "1909-Sarah-Orne-Jewett 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.15088728 0.84911272]]\n",
      "\n",
      "100\n",
      "1987-Clare-Boothe-Luce 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[6.19514596e-04 9.99380485e-01]]\n",
      "\n",
      "101\n",
      "1962-Marilyn-Monroe 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00106837 0.99893163]]\n",
      "\n",
      "102\n",
      "1964-Rachel-Carson 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.16626539 0.83373461]]\n",
      "\n",
      "103\n",
      "1953-Marjorie-Rawlings 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.56210026 0.43789974]]\n",
      "\n",
      "104\n",
      "1963-Sylvia-Plath 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00333813 0.99666187]]\n",
      "\n",
      "105\n",
      "1982-Anna-Freud 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.14210091 0.85789909]]\n",
      "\n",
      "106\n",
      "1901-Queen-Victoria 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.95692651 0.04307349]]\n",
      "\n",
      "107\n",
      "1961-Primitive-Artist 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.09860885 0.90139115]]\n",
      "\n",
      "108\n",
      "1971-Diane-Arbus 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.02277727 0.97722273]]\n",
      "\n",
      "109\n",
      "1969-Judy-Garland 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.01947226 0.98052774]]\n",
      "\n",
      "110\n",
      "1995-Ginger-Rogers 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.01741157e-04 9.99798259e-01]]\n",
      "\n",
      "111\n",
      "1920-Marlene-Dietrich 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 1\n",
      "Prediction is: [1] [[1.86619781e-06 9.99998134e-01]]\n",
      "\n",
      "112\n",
      "1992-Marsha-P-Johnson 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.6290889 0.3709111]]\n",
      "\n",
      "113\n",
      "1951-Fanny-Brice 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00346189 0.99653811]]\n",
      "\n",
      "114\n",
      "1989-Lucille-Ball 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00987049 0.99012951]]\n",
      "\n",
      "115\n",
      "1969-Sonja-Henie 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.15626216 0.84373784]]\n",
      "\n",
      "116\n",
      "1941-Virginia-Woolf 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.07297939 0.92702061]]\n",
      "\n",
      "117\n",
      "1907-Qiu-Jin 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.37716616e-09 9.99999999e-01]]\n",
      "\n",
      "118\n",
      "1971-Florence-Blanchfield 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.20381989 0.79618011]]\n",
      "\n",
      "119\n",
      "1902-Elizabeth-Cady-Stanton 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[8.35831404e-11 1.00000000e+00]]\n",
      "\n",
      "120\n",
      "1965-Shirley-Jackson 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00159949 0.99840051]]\n",
      "\n",
      "121\n",
      "1919-C-J-Walker 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.21866083 0.78133917]]\n",
      "\n",
      "122\n",
      "1949-Mitchell 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.36897068 0.63102932]]\n",
      "\n",
      "123\n",
      "1951-Henrietta-Lacks 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.0011827 0.9988173]]\n",
      "\n",
      "124\n",
      "1937-Edith-Wharton 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[7.41597018e-05 9.99925840e-01]]\n",
      "\n",
      "125\n",
      "1935-Jane-Addams 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.11022302e-15 1.00000000e+00]]\n",
      "\n",
      "126\n",
      "1973-Jeanette-Rankin 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 1\n",
      "Prediction is: [1] [[1.26879872e-08 9.99999987e-01]]\n",
      "\n",
      "127\n",
      "1888-Louisa-M-Alcott 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.0012887 0.9987113]]\n",
      "\n",
      "128\n",
      "1986-Georgia-O-Keeffe 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.8957060e-07 9.9999971e-01]]\n",
      "\n",
      "129\n",
      "1978-Margaret-Mead 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.98317437 0.01682563]]\n",
      "\n",
      "130\n",
      "1982-Ingrid-Bergman 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00357452 0.99642548]]\n",
      "\n",
      "131\n",
      "1977-Maria-Callas 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.6441851 0.3558149]]\n",
      "\n",
      "132\n",
      "1952-Eva-Peron 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00140041 0.99859959]]\n",
      "\n",
      "133\n",
      "1961-Emily-Balch 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00347989 0.99652011]]\n",
      "\n",
      "134\n",
      "1896-Harriet-Beecher-Stowe 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[5.24164089e-06 9.99994758e-01]]\n",
      "\n",
      "135\n",
      "1969-Madhubala 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00246769 0.99753231]]\n",
      "\n",
      "136\n",
      "1950-Edna-St-V-Millay 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.60598603 0.39401397]]\n",
      "\n",
      "137\n",
      "1929-Marie-Curie 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.03009810e-05 9.99979699e-01]]\n",
      "\n",
      "138\n",
      "1998-Helen-Moody 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.52206667 0.47793333]]\n",
      "\n",
      "139\n",
      "1936-Anne-Macy 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.21319722 0.78680278]]\n",
      "\n",
      "140\n",
      "1880-Lucretia-Mott 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00586825 0.99413175]]\n",
      "\n",
      "141\n",
      "1922-Nellie-Bly 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.56861084 0.43138916]]\n",
      "\n",
      "142\n",
      "1968-Helen-Keller 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 1\n",
      "Prediction is: [1] [[0.02882269 0.97117731]]\n",
      "\n",
      "143\n",
      "1966-Margaret-Sanger 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.41345323e-08 9.99999976e-01]]\n",
      "\n",
      "144\n",
      "1972-Mahalia-Jackson 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[7.18332261e-05 9.99928167e-01]]\n",
      "\n",
      "145\n",
      "1990-Greta-Garbo 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[5.52589308e-10 9.99999999e-01]]\n",
      "\n",
      "146\n",
      "1994-Jessica-Tandy 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.01936142 0.98063858]]\n",
      "\n",
      "147\n",
      "1969-Maureen-Connolly 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[8.12054050e-04 9.99187946e-01]]\n",
      "\n",
      "148\n",
      "1991-Peggy-Ashcroft 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.3352565 0.6647435]]\n",
      "\n",
      "149\n",
      "1946-Gertrude-Stein 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.41409909 0.58590091]]\n",
      "\n",
      "150\n",
      "1887-Emma-Lazarus 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.34720682 0.65279318]]\n",
      "\n",
      "151\n",
      "1977-Joan-Crawford 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.83018053e-12 1.00000000e+00]]\n",
      "\n",
      "152\n",
      "1906-Susan-B-Anthony 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[6.86398050e-10 9.99999999e-01]]\n",
      "\n",
      "153\n",
      "1954-Anne-O-Hare-McCormick 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[3.21117054e-05 9.99967888e-01]]\n",
      "\n",
      "154\n",
      "1986-Kate-Smith 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.93780123 0.06219877]]\n",
      "\n",
      "155\n",
      "1919-Anna-H-Shaw 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.17028609e-11 1.00000000e+00]]\n",
      "\n",
      "156\n",
      "1931-Ida-B-Wells 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.07855754 0.92144246]]\n",
      "\n",
      "157\n",
      "1973-Nancy-Mitford 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.34952236 0.65047764]]\n",
      "\n",
      "158\n",
      "1852-Ada-Lovelace 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.01008018 0.98991982]]\n",
      "\n",
      "159\n",
      "1998-Maureen-O-Sullivan 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 1\n",
      "Prediction is: [1] [[0.22576056 0.77423944]]\n",
      "\n",
      "160\n",
      "1975-Haile-Selassie 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.9986789 0.0013211]]\n",
      "\n",
      "161\n",
      "1903-Emily-Warren-Roebling 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.36168726e-04 9.99863831e-01]]\n",
      "\n",
      "162\n",
      "1962-Eleanor-Roosevelt 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.30928175e-05 9.99976907e-01]]\n",
      "\n",
      "163\n",
      "1971-Coco-Chanel 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.63999875 0.36000125]]\n",
      "\n",
      "164\n",
      "1959-Billie-Holiday 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.11151153 0.88848847]]\n",
      "\n",
      "165\n",
      "1954-Frida-Kahlo 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.01190255 0.98809745]]\n",
      "\n",
      "166\n",
      "1927-Victoria-Martin 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.72254091e-05 9.99982775e-01]]\n",
      "\n",
      "167\n",
      "1959-Ethel-Barrymore 1\n",
      "Class is: 1\n",
      "Prediction is: [0] [[0.8974851 0.1025149]]\n",
      "\n",
      "168\n",
      "1999-Iris-Murdoch 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00704369 0.99295631]]\n",
      "\n",
      "169\n",
      "1998-Bella-Abzug 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[4.48665549e-11 1.00000000e+00]]\n",
      "\n",
      "170\n",
      "1944-Ida-M-Tarbell 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.23693805 0.76306195]]\n",
      "\n",
      "171\n",
      "1992-Shirley-Booth 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00450893 0.99549107]]\n",
      "\n",
      "172\n",
      "1994-Jacqueline-Kennedy 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.52205885e-04 9.99847794e-01]]\n",
      "\n",
      "173\n",
      "1974-Sylvia-Plath 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[1.22984966e-06 9.99998770e-01]]\n",
      "\n",
      "174\n",
      "1960-Emily-Post 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.31360484 0.68639516]]\n",
      "\n",
      "175\n",
      "1956-Babe-Zaharias 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[4.65085741e-06 9.99995349e-01]]\n",
      "\n",
      "176\n",
      "1947-Willa-Cather 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class is: 1\n",
      "Prediction is: [0] [[0.82612156 0.17387844]]\n",
      "\n",
      "177\n",
      "1984-Indira-Gandhi 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[2.05817611e-04 9.99794182e-01]]\n",
      "\n",
      "178\n",
      "1978-Golda-Meir 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[7.55112062e-06 9.99992449e-01]]\n",
      "\n",
      "179\n",
      "1974-Katharine-Cornell 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.00315108 0.99684892]]\n",
      "\n",
      "180\n",
      "1886-Mary-Ewing-Outerbridge 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.47597005 0.52402995]]\n",
      "\n",
      "181\n",
      "1910-Florence-Nightingale 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[3.12202620e-08 9.99999969e-01]]\n",
      "\n",
      "182\n",
      "1986-The-Challenger 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.07456909 0.92543091]]\n",
      "\n",
      "183\n",
      "1998-Galina-Ulanova 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.26420843 0.73579157]]\n",
      "\n",
      "184\n",
      "1987-Rita-Hayworth 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.2891711 0.7108289]]\n",
      "\n",
      "185\n",
      "1932-Florenz-Ziegfeld 1\n",
      "Class is: 1\n",
      "Prediction is: [1] [[0.06412618 0.93587382]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for this_index in df_final.index.tolist():\n",
    "    print(this_index) # keep track of where we are in the corpus\n",
    "    title = meta.loc[meta.index[this_index], 'obit_title'] \n",
    "    CLASS = meta.loc[meta.index[this_index], 'gender']\n",
    "    print(title, CLASS) \n",
    "    \n",
    "    train_index_list = [index_ for index_ in df.index.tolist() if index_ != this_index] # exclude the title to be predicted\n",
    "    X = df.loc[train_index_list] # the model trains on all the data except the excluded title row\n",
    "    y = meta.loc[train_index_list, 'gender'] # the y row tells the model which class each title belongs to\n",
    "    TEST_CASE = df.loc[[this_index]]\n",
    "\n",
    "    model.fit(X,y) # fit the model\n",
    "    prediction = model.predict_proba(TEST_CASE) # calculate probability of test case\n",
    "    predicted = model.predict(TEST_CASE) # calculate predicted class of test case\n",
    "    meta.at[this_index, 'PREDICTED'] = predicted # add predicted class to metadata\n",
    "    meta.at[this_index, 'PROBS'] = str(prediction) # add probabilities to metadata\n",
    "    print('Class is: ' + str(CLASS) + '\\n' + 'Prediction is: ' + str(predicted) + ' ' + str(prediction) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How cool is this! For each obituary, we see who it's about, that person's gender (0 or 1), and which gender the model thinks it's about, by which probabilities. \n",
    "\n",
    "What can you glean by glancing through?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE\n",
    "* *\n",
    "* *\n",
    "* *\n",
    "* *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we've stored our results in our metadata dataframe. Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>PROBS</th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1936-John-W-Heisman</td>\n",
       "      <td>0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>[[0.79355842 0.20644158]]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1971-Dean-Acheson</td>\n",
       "      <td>0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>[[9.99999779e-01 2.21229604e-07]]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1970-Edouard-Daladier</td>\n",
       "      <td>0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>[[0.98035948 0.01964052]]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1995-Jonas-Salk</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>[[9.99988000e-01 1.19995998e-05]]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1988-John-Houseman</td>\n",
       "      <td>0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>[[0.39230848 0.60769152]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1910-Florence-Nightingale</td>\n",
       "      <td>1</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>[[3.12202620e-08 9.99999969e-01]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1986-The-Challenger</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>[[0.07456909 0.92543091]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1998-Galina-Ulanova</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[[0.26420843 0.73579157]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>[[0.2891711 0.7108289]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>[[0.06412618 0.93587382]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    obit_title  gender    date  \\\n",
       "0          1936-John-W-Heisman       0  1936.0   \n",
       "1            1971-Dean-Acheson       0  1971.0   \n",
       "2        1970-Edouard-Daladier       0  1946.0   \n",
       "3              1995-Jonas-Salk       0  1995.0   \n",
       "4           1988-John-Houseman       0  1988.0   \n",
       "..                         ...     ...     ...   \n",
       "181  1910-Florence-Nightingale       1  1854.0   \n",
       "182        1986-The-Challenger       1  1986.0   \n",
       "183        1998-Galina-Ulanova       1  1998.0   \n",
       "184         1987-Rita-Hayworth       1  1987.0   \n",
       "185      1932-Florenz-Ziegfeld       1  1932.0   \n",
       "\n",
       "                                 PROBS PREDICTED  \n",
       "0            [[0.79355842 0.20644158]]       [0]  \n",
       "1    [[9.99999779e-01 2.21229604e-07]]       [0]  \n",
       "2            [[0.98035948 0.01964052]]       [0]  \n",
       "3    [[9.99988000e-01 1.19995998e-05]]       [0]  \n",
       "4            [[0.39230848 0.60769152]]       [1]  \n",
       "..                                 ...       ...  \n",
       "181  [[3.12202620e-08 9.99999969e-01]]       [1]  \n",
       "182          [[0.07456909 0.92543091]]       [1]  \n",
       "183          [[0.26420843 0.73579157]]       [1]  \n",
       "184            [[0.2891711 0.7108289]]       [1]  \n",
       "185          [[0.06412618 0.93587382]]       [1]  \n",
       "\n",
       "[186 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's lots to look at here. We could explore probabilities: which obituaries is the model most sure about? Which are closest to 50-50? Which does it get most right and most wrong? Is there a pattern to misclassified obituaries?\n",
    "\n",
    "For now, we just want to calculate its accuracy. Let's get rid of those brackets in the PREDICTED column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>PROBS</th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1936-John-W-Heisman</td>\n",
       "      <td>0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>[[0.79355842 0.20644158]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1971-Dean-Acheson</td>\n",
       "      <td>0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>[[9.99999779e-01 2.21229604e-07]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1970-Edouard-Daladier</td>\n",
       "      <td>0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>[[0.98035948 0.01964052]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1995-Jonas-Salk</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>[[9.99988000e-01 1.19995998e-05]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1988-John-Houseman</td>\n",
       "      <td>0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>[[0.39230848 0.60769152]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1910-Florence-Nightingale</td>\n",
       "      <td>1</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>[[3.12202620e-08 9.99999969e-01]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1986-The-Challenger</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>[[0.07456909 0.92543091]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1998-Galina-Ulanova</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[[0.26420843 0.73579157]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>[[0.2891711 0.7108289]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>[[0.06412618 0.93587382]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    obit_title  gender    date  \\\n",
       "0          1936-John-W-Heisman       0  1936.0   \n",
       "1            1971-Dean-Acheson       0  1971.0   \n",
       "2        1970-Edouard-Daladier       0  1946.0   \n",
       "3              1995-Jonas-Salk       0  1995.0   \n",
       "4           1988-John-Houseman       0  1988.0   \n",
       "..                         ...     ...     ...   \n",
       "181  1910-Florence-Nightingale       1  1854.0   \n",
       "182        1986-The-Challenger       1  1986.0   \n",
       "183        1998-Galina-Ulanova       1  1998.0   \n",
       "184         1987-Rita-Hayworth       1  1987.0   \n",
       "185      1932-Florenz-Ziegfeld       1  1932.0   \n",
       "\n",
       "                                 PROBS  PREDICTED  \n",
       "0            [[0.79355842 0.20644158]]          0  \n",
       "1    [[9.99999779e-01 2.21229604e-07]]          0  \n",
       "2            [[0.98035948 0.01964052]]          0  \n",
       "3    [[9.99988000e-01 1.19995998e-05]]          0  \n",
       "4            [[0.39230848 0.60769152]]          1  \n",
       "..                                 ...        ...  \n",
       "181  [[3.12202620e-08 9.99999969e-01]]          1  \n",
       "182          [[0.07456909 0.92543091]]          1  \n",
       "183          [[0.26420843 0.73579157]]          1  \n",
       "184            [[0.2891711 0.7108289]]          1  \n",
       "185          [[0.06412618 0.93587382]]          1  \n",
       "\n",
       "[186 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.replace([0], 0)\n",
    "meta = meta.replace([1], 1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add a 'RESULT' column that is the result of subtracting the predicted gender from the actual gender.\n",
    "\n",
    "0 means the model was correct.\n",
    "-1 means the model mistook a man for a woman.\n",
    "1 means the model mistook a woman for a man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>PROBS</th>\n",
       "      <th>PREDICTED</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1936-John-W-Heisman</td>\n",
       "      <td>0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>[[0.79355842 0.20644158]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1971-Dean-Acheson</td>\n",
       "      <td>0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>[[9.99999779e-01 2.21229604e-07]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1970-Edouard-Daladier</td>\n",
       "      <td>0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>[[0.98035948 0.01964052]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1995-Jonas-Salk</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>[[9.99988000e-01 1.19995998e-05]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1988-John-Houseman</td>\n",
       "      <td>0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>[[0.39230848 0.60769152]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1910-Florence-Nightingale</td>\n",
       "      <td>1</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>[[3.12202620e-08 9.99999969e-01]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1986-The-Challenger</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>[[0.07456909 0.92543091]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1998-Galina-Ulanova</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[[0.26420843 0.73579157]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>[[0.2891711 0.7108289]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>[[0.06412618 0.93587382]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    obit_title  gender    date  \\\n",
       "0          1936-John-W-Heisman       0  1936.0   \n",
       "1            1971-Dean-Acheson       0  1971.0   \n",
       "2        1970-Edouard-Daladier       0  1946.0   \n",
       "3              1995-Jonas-Salk       0  1995.0   \n",
       "4           1988-John-Houseman       0  1988.0   \n",
       "..                         ...     ...     ...   \n",
       "181  1910-Florence-Nightingale       1  1854.0   \n",
       "182        1986-The-Challenger       1  1986.0   \n",
       "183        1998-Galina-Ulanova       1  1998.0   \n",
       "184         1987-Rita-Hayworth       1  1987.0   \n",
       "185      1932-Florenz-Ziegfeld       1  1932.0   \n",
       "\n",
       "                                 PROBS  PREDICTED  RESULT  \n",
       "0            [[0.79355842 0.20644158]]          0       0  \n",
       "1    [[9.99999779e-01 2.21229604e-07]]          0       0  \n",
       "2            [[0.98035948 0.01964052]]          0       0  \n",
       "3    [[9.99988000e-01 1.19995998e-05]]          0       0  \n",
       "4            [[0.39230848 0.60769152]]          1      -1  \n",
       "..                                 ...        ...     ...  \n",
       "181  [[3.12202620e-08 9.99999969e-01]]          1       0  \n",
       "182          [[0.07456909 0.92543091]]          1       0  \n",
       "183          [[0.26420843 0.73579157]]          1       0  \n",
       "184            [[0.2891711 0.7108289]]          1       0  \n",
       "185          [[0.06412618 0.93587382]]          1       0  \n",
       "\n",
       "[186 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_column = meta['gender'] - meta['PREDICTED']\n",
    "meta['RESULT'] = sum_column\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the accurate guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obit_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>PROBS</th>\n",
       "      <th>PREDICTED</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1936-John-W-Heisman</td>\n",
       "      <td>0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>[[0.79355842 0.20644158]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1971-Dean-Acheson</td>\n",
       "      <td>0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>[[9.99999779e-01 2.21229604e-07]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1970-Edouard-Daladier</td>\n",
       "      <td>0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>[[0.98035948 0.01964052]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1995-Jonas-Salk</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>[[9.99988000e-01 1.19995998e-05]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1968-Yuri-Gagarin</td>\n",
       "      <td>0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>[[0.80787114 0.19212886]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1910-Florence-Nightingale</td>\n",
       "      <td>1</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>[[3.12202620e-08 9.99999969e-01]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1986-The-Challenger</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>[[0.07456909 0.92543091]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1998-Galina-Ulanova</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[[0.26420843 0.73579157]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1987-Rita-Hayworth</td>\n",
       "      <td>1</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>[[0.2891711 0.7108289]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1932-Florenz-Ziegfeld</td>\n",
       "      <td>1</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>[[0.06412618 0.93587382]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    obit_title  gender    date  \\\n",
       "0          1936-John-W-Heisman       0  1936.0   \n",
       "1            1971-Dean-Acheson       0  1971.0   \n",
       "2        1970-Edouard-Daladier       0  1946.0   \n",
       "3              1995-Jonas-Salk       0  1995.0   \n",
       "5            1968-Yuri-Gagarin       0  1968.0   \n",
       "..                         ...     ...     ...   \n",
       "181  1910-Florence-Nightingale       1  1854.0   \n",
       "182        1986-The-Challenger       1  1986.0   \n",
       "183        1998-Galina-Ulanova       1  1998.0   \n",
       "184         1987-Rita-Hayworth       1  1987.0   \n",
       "185      1932-Florenz-Ziegfeld       1  1932.0   \n",
       "\n",
       "                                 PROBS  PREDICTED  RESULT  \n",
       "0            [[0.79355842 0.20644158]]          0       0  \n",
       "1    [[9.99999779e-01 2.21229604e-07]]          0       0  \n",
       "2            [[0.98035948 0.01964052]]          0       0  \n",
       "3    [[9.99988000e-01 1.19995998e-05]]          0       0  \n",
       "5            [[0.80787114 0.19212886]]          0       0  \n",
       "..                                 ...        ...     ...  \n",
       "181  [[3.12202620e-08 9.99999969e-01]]          1       0  \n",
       "182          [[0.07456909 0.92543091]]          1       0  \n",
       "183          [[0.26420843 0.73579157]]          1       0  \n",
       "184            [[0.2891711 0.7108289]]          1       0  \n",
       "185          [[0.06412618 0.93587382]]          1       0  \n",
       "\n",
       "[157 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_correct = meta[meta['RESULT'] == 0]\n",
    "meta_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many did the model get correct?\n",
    "\n",
    "We can calculate its accuracy by dividing the correct number by the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good rate! At random, the model should guess correctly 50% of the time. It does **much** better than that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-values and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are significant words that distinguish men: []\n",
      "Here are significant words that distinguish women: ['woman', 'women', 'husband']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "canonic_c = 1.0\n",
    "\n",
    "def Ztest(vec1, vec2):\n",
    "\n",
    "    X1, X2 = np.mean(vec1), np.mean(vec2)\n",
    "    sd1, sd2 = np.std(vec1), np.std(vec2)\n",
    "    n1, n2 = len(vec1), len(vec2)\n",
    "\n",
    "    pooledSE = np.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = (X1 - X2)/pooledSE\n",
    "    pval = 2*(norm.sf(abs(z)))\n",
    "\n",
    "    return z, pval\n",
    "\n",
    "def feat_pval_weight(meta_df_, dtm_df_):\n",
    "    \n",
    "    #dtm_df_ = dtm_df_.loc[meta_df_.index.tolist()]\n",
    "    #dtm_df_ = normalize_model(dtm_df_, dtm_df_)[0]\n",
    "    #dtm_df_ = dtm_df_.dropna(axis = 1, how='any')\n",
    "\n",
    "    dtm0 = dtm_df_.loc[meta_df_[meta_df_['gender']==0].index.tolist()].to_numpy()\n",
    "    dtm1 = dtm_df_.loc[meta_df_[meta_df_['gender']==1].index.tolist()].to_numpy()\n",
    "\n",
    "    pvals = [Ztest(dtm0[ : ,i], dtm1[ : ,i])[1] for i in range(dtm_df_.shape[1])]\n",
    "    clf = LogisticRegression(penalty = 'l1', C = canonic_c, class_weight = 'balanced')\n",
    "    clf.fit(dtm_df_, meta_df_['gender']==0)\n",
    "    weights = clf.coef_[0]\n",
    "\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    feature_df['FEAT'] = dtm_df_.columns\n",
    "    feature_df['P_VALUE'] = pvals\n",
    "    feature_df['LR_WEIGHT'] = weights\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "sig_thresh = 0.05 / len(df.columns)\n",
    "\n",
    "feat_df = feat_pval_weight(meta, df)\n",
    "\n",
    "feat_df.to_csv('../docs/features_obits.csv')\n",
    "out = feat_df[(feat_df['P_VALUE'] <= sig_thresh)].sort_values('LR_WEIGHT', ascending = True)\n",
    "out = out[out['LR_WEIGHT'] != 0]\n",
    "outM = out[out['LR_WEIGHT'] >= 0]\n",
    "outW = out[out['LR_WEIGHT'] <= 0]\n",
    "\n",
    "outM = outM['FEAT'].tolist()\n",
    "print(\"Here are significant words that distinguish men: \" + str(outM))\n",
    "outW = outW['FEAT'].tolist()\n",
    "print(\"Here are significant words that distinguish women: \" + str(outW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
