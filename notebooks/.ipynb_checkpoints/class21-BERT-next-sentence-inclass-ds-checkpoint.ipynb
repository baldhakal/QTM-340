{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT for next sentence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ted Underwood wrote version 1.0 of this notebook, which I have lightly revised_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First we import `torch` and `transformers` and load everything and get it ready to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print('built tokenizer')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "print('built model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write function to predict next sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function to do next sentence prediction. We use HuggingFace's [`tokenizer`](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus) and PyTorch's [`LongTensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor). \n",
    "\n",
    "NB: A `tensor` [is a multi-dimensional array](https://www.tensorflow.org/guide/tensor).\n",
    "\n",
    "Don't worry if you can't wrap your head around the math underlying all thisâ€”it's beyond our pay grade in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(firstsentence, secondsentence):\n",
    "    global tokenizer, model\n",
    "\n",
    "    encoding = tokenizer.encode_plus(firstsentence, secondsentence, return_tensors = 'pt')\n",
    "    loss, logits = model(**encoding, next_sentence_label=torch.LongTensor([1]))\n",
    "\n",
    "    return loss, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsentence = \"I was walking to the store one day to buy groceries.\"\n",
    "secondsentence = \"At the store I bought bananas and milk.\"\n",
    "\n",
    "get_logits(firstsentence, secondsentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. What the hell does that mean? The first line is the \"loss,\" the second the \"logits.\" The relation between logits and probability makes my head hurt to explain, so I'm just going to [point at Wikipedia.](https://en.wikipedia.org/wiki/Logit)\n",
    "\n",
    "But for a quick and dirty approach, Ted Underwood wrote this function that *loosely* translates BERT's logits output into a probability for the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_probability(firstsent, secondsent):\n",
    "    '''\n",
    "    \n",
    "    :param logits: a tensor produced by BERT\n",
    "    :return: probability of the first category after softmax\n",
    "    '''\n",
    "    loss, logits = get_logits(firstsent, secondsent)\n",
    "    \n",
    "    poslogit = logits[0, 0]\n",
    "    neglogit = logits[0, 1]\n",
    "\n",
    "    pospart = math.pow(1.2, poslogit)\n",
    "    negpart = math.pow(1.2, neglogit)\n",
    "\n",
    "    posprob = pospart / (pospart + negpart)\n",
    "\n",
    "    return posprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try again with the new function to make the result comprehensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsentence = \"I was walking to the store one day to buy groceries.\"\n",
    "secondsentence = \"At the store I bought bananas and milk.\"\n",
    "\n",
    "get_probability(firstsentence, secondsentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, now we can see that BERT considers that a pretty probable sequence. Let's try a less probable sequence.\n",
    "\n",
    "We'll use the same first sentence about walking to the store, and for our second sentence\n",
    "\n",
    "    Psychedelics are a hallucinogenic class of psychoactive drug whose primary effect is to trigger non-ordinary states of consciousness and psychedelic experiences via serotonin 2A receptor agonism.\n",
    "    \n",
    "Which is from Wikipedia on \"psychedelic drug.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsentence = \"I was walking to the store one day to buy groceries.\"\n",
    "secondsentence = \"Psychedelics are a hallucinogenic class of psychoactive drug whose primary effect is to trigger non-ordinary states of consciousness and psychedelic experiences via serotonin 2A receptor agonism.\"\n",
    "get_probability(firstsentence, secondsentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a much less probable sequence! Let's try a slightly weaker non-sequitur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsentence = \"I was walking to the store one day to buy groceries.\"\n",
    "secondsentence = \"Everything is closed due to the pandemic.\"\n",
    "get_probability(firstsentence, secondsentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that probability is higher. Still unlikely. But not *totally* improbable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a variety of sentences in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsentence = \"I was walking to the store one day to buy groceries.\"\n",
    "secondsentence = \"YOUR SENTENCE\"\n",
    "get_probability(firstsentence, secondsentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now write both sentences yourself: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsentence = \"YOUR SENTENCE\"\n",
    "secondsentence = \"YOUR SENTENCE\"\n",
    "get_probability(firstsentence, secondsentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Did the model perform as you expected? Did it surprise you? What uses can you imagine putting this model to? How could we fit it into a larger pipeline toward some further tasks or analysees?\n",
    "\n",
    "#### YOUR ANALYSIS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
