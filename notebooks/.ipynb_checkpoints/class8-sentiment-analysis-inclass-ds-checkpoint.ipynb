{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with NLP and Sentiment Analysis ##\n",
    "\n",
    "*Lauren F. Klein wrote version 1.0 of this notebook, based off [Sentiment Analysis for Exploratory Data Analysis](https://programminghistorian.org/en/lessons/sentiment-analysis) by Zöe Wilkinson Saldaña with additional info by [Parul Pandey](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f).*\n",
    "\n",
    "Thus far, we have learned to access APIs, scrape, parse, and clean text. We're ready for NLP.\n",
    "\n",
    "But what's NLP?\n",
    "\n",
    "Natural Language Processing (NLP) names a broad range of techniques that involve applying computational analytical methods to text. (\"Natural language\" in this context just means human language as opposed to a programming language, like Python). In this unit, we'll explore many popular NLP techniques, beginning with sentiment analysis. \n",
    "\n",
    "Sentiment analysis is a method of quantifying the \"sentiment,\" or emotional intensity, of words and phrases in a text. Some sentiment analysis tools, including the one we'll be working with today, also factor in the emotional weight of other features of language, such as punctuation marks or emojis. In general, sentiment analysis processes a unit of text (a sentence, a paragraph, a book, an email, a song, a tweet) and outputs scores or other classifications that indicate whether that unit of text conveys a positive or negative sentiment (according to the particular algorithm and dictionary employed). Some tools go as far as to quantify the *degree* of positivity or degree of negativity within a text. \n",
    "\n",
    "How might this be helpful? A researcher interested in attitudes toward a political event, for example, might use sentiment analysis to characterize how people describe that event on Twitter. Combined with geographic data, sentiment analysis can be used to make comparisons across regions. Combined with demographic data, sentiment analysis can be used to understand how different groups of people view any particular event (or issue, or individual). Sentiment analysis can be easily scaled up, which makes it possible to analyze hundreds of thousands or even millions of speech events.\n",
    "\n",
    "Like any computational tool, sentiment analysis has limitations that must be taken into account. We'll explore some of those in our readings and Canvas discussion. But when wielding sentiment analysis critically *and* creatively, it can lead to interesting results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK and VADER ###\n",
    "\n",
    "You will be using a few tools from Python's [NLTK](https://www.nltk.org/) (short for Natural Language Toolkit) to generate sentiment scores for the corpus that we created in Unit 1: the lyrics of the candidate playlists that we scraped from Genius.com. After completing today's other Jupyter notebook, you should have those lyrics in a directory on your computer.\n",
    "\n",
    "NLTK is a collection of libraries and tools that help researchers apply computational methods to texts. It's been in development since 2001--almost as old as you (or older)!--and it's used widely in the field of NLP. The tools included in NLTK range from methods of breaking up text into smaller pieces, to identifying whether a word belongs in a given language, to providing sample corpora (that's the plural of corpus) that researchers can use for training and development purposes. We'll be using NLTK a lot in the coming weeks. As with the previous unit, I'll introduce you to its features as we require them for our specific goals.   \n",
    "\n",
    "Today, we will be using one NLTK tool: [VADER](https://github.com/cjhutto/vaderSentiment) (short for Valence Aware Dictionary and sEntiment Reasoner), which generates positive, negative, and neutral sentiment scores for textual input.\n",
    "\n",
    "VADER has a lot of advantages over traditional methods of sentiment analysis, including:\n",
    "* It works well on social media text, yet readily generalizes to multiple domains;\n",
    "* It doesn’t require training data but is constructed from a generalizable, valence-based, human-curated gold standard sentiment lexicon;\n",
    "* It is fast enough to be used online with streaming data, and;\n",
    "* It does not severely suffer from a speed-performance tradeoff.\n",
    "\n",
    "The source of the above is an easy-to-read paper published by the creaters of VADER library, one of whom use to work at Georgia Tech. You can read it [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Lexicons, Sentiment Intensity, and Context-Awareness ###\n",
    "\n",
    "Traditionally, sentiment analysis worked by comparing text to a list of lexical features (i.e. words) that were determined by people to be either positive or negative. These are known as *sentiment lexicons.* (It's possible to create lexicons for other types of language as well; we'll talk about this more in Unit 3, when we discuss modeling.) \n",
    "\n",
    "More recently, tools have improved upon the positive/negative binary by offering more fine-tuned distinctions between varying degrees of positivity and negativity. This is known as *sentiment intensity*, and VADER does this well. For example, VADER scores “comfort” as moderately positive and “euphoria” as extremely positive. \n",
    "\n",
    "VADER also attempts to capture and score textual features common in informal online text such as capitalizations, exclamation points, and emoticons, as shown in the table below:\n",
    "\n",
    "![VADER table](https://programminghistorian.org/images/sentiment-analysis/sentiment-analysis1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat Emptor! ###\n",
    "\n",
    "Like any text analysis tool, VADER should be evaluated critically and in the context of the assumptions it makes about communication. VADER was developed to analyze English language microblogging and social media sites (especially Twitter). This context is more informal than, for instance, political speeches; and more contemporary than, for instance, Shakespeare. But VADER was also developed as a general purpose sentiment analyzer, and the authors’ initial study shows it compares favorably against tools that have been trained for specific domains, use specialized lexicons, or resource-heavy machine learning techniques. That said, sentiment analysis continues to struggle to capture complex sentiments like irony, sarcasm, and mockery, when the average reader would be able to make the distinction between the literal text and its intended meaning.\n",
    "\n",
    "A few more caveats: while VADER is a good general purpose tool for English language texts, VADER only provides partial native support for non-English texts (it detects emojis/capitalization/etc., but not word choice). The developers encourage users to use automatic translation to pre-process non-English texts and then input the results into VADER. There might be better tools for non-English langauge texts. \n",
    "\n",
    "### Some examples of hard-to-classify sentences ###\n",
    "\n",
    "“The premise of the film was great, but it could have been better.”\n",
    "“The best I can say about the movie is that it was interesting.”\n",
    "\n",
    "* What words would you identify as being associated with either positive or negative sentiment?\n",
    "    * ANSWER HERE\n",
    "* Would you say that these sentence have a positive or negative seniment? \n",
    "    * ANSWER HERE\n",
    "* What are some reasons that these sentence might be tricky for a sentiment analysis tool?\n",
    "    * ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enough Talk, Time for Action! ###\n",
    "\n",
    "To use VADER, we need to import the nltk library and download and install the VADER lexicon. You do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt') # took this out of today's lesson "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a sense of what VADER can do, let’s calculate the sentiment scores for one of the songs we scraped from Genius.com.\n",
    "\n",
    "The main component of VADER is its SentimentIntensityAnalyzer, so let's import that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You can ignore the warning, if you get it, about not having twython installed). \n",
    "\n",
    "Technically, SentimentIntensityAnalyzer is a class, which we will use to build our own sentiment analyzer object.\n",
    "\n",
    "To do so, we call SentimentIntensityAnalyzer() and assign the output - our brand-new sentiment analyzer - to a variable, which we will name ‘sid’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this we have given \"sid\" all of the features of the VADER sentiment analysis object. It has become our sentiment analysis tool, but by a shorter name.\n",
    "\n",
    "Now, let's open up one of the lyrics files we created. **Be sure that you have a folder titled 'lyrics' in the same folder with this notebook on your computer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./lyrics/Aretha-franklin-respect.txt\", \"r\") as file:\n",
    "    lyrics = file.read()\n",
    "\n",
    "# and just to be sure, print out what we've loaded in:\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want what is called the ‘polarity score,’ which is either positive or negative. \n",
    "\n",
    "Calling the polarity_scores method on sid with our lyrics (or any string) outputs a dictionary with negative, neutral, positive, and compound scores for the input text. Let's do a test with some recent political slogans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(\"Make America Great Again\")\n",
    "\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(\"Stronger Together\")\n",
    "\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(\"Hope and Change\")\n",
    "\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the lyrics of \"Respect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(lyrics)\n",
    "\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! We just performed our first text analysis! \n",
    "\n",
    "But how do we analyze the analysis?\n",
    "\n",
    "VADER collects and scores negative, neutral, and positive words and features (and accounts for factors like negation along the way). The “neg”, “neu”, and “pos” values describe the fraction of weighted scores that fall into each category. In this case, VADER determined our song lyrics to consist of 3.5% negative words/features, 87.5% neutral words/features, and 9% positive words/features. \n",
    "\n",
    "VADER also sums all weighted scores to calculate a compound value normalized between -1 and 1; this value attempts to describe the overall sentiment of the entire chunk of text from strongly negative (-1) to strongly positive (1). In this case, the VADER analysis describes the song as strongly positive (.9342). We can think of this value as estimating the overall impression of an average listener when considering the song as a whole.\n",
    "\n",
    "This [post](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f) has a bit more about how VADER calculates its scores.  \n",
    "\n",
    "Let's [listen to the song](https://www.youtube.com/watch?v=6FOUqQt3Kg0) and see if we agree. \n",
    "\n",
    "### A Quick Note on Thresholds ###\n",
    "\n",
    "It can be helpful to set a minimum threshold for positivity or negativity so that you can classify a text either positive or negative. The official VADER documentation suggests a threshold of -0.5 and 0.5, meaning to be counted negative it should be below -0.5 and as positive above 0.5. \"Respect\" easily meets this threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how \"Respect\" compares to another song, let's try \"Dis Generation\" by A Tribe Called Quest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./lyrics/A-tribe-called-quest-dis-generation.txt\", \"r\") as file:\n",
    "    lyrics2 = file.read()\n",
    "    \n",
    "# and just to be sure, print out what we've loaded in:\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = sid.polarity_scores(lyrics2)\n",
    "\n",
    "for key in sorted(scores2):\n",
    "    print('{0}: {1}, '.format(key, scores2[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! VADER sees \"Dis Generation\" as very negative. Listen for yourself [here](https://www.youtube.com/watch?v=kQaSDJYwdh4). Do you agree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Appropriate Scope ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much calibration, or pre-processing, required of sentiment analysis. But there is one important aspect of calibration to consider when employing sentiment analysis: the unit of the text being analyzed.\n",
    "\n",
    "In the case of song lyrics, for example, we might want to analyze the entire song as a single unit, or we might want to analyze each line. \n",
    "\n",
    "* What are some research questions for which you might want to look at the entire song as a whole?\n",
    "* What are some research questions for which you might want to look at each line at a time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redo our sentiment analysis so that we look at each line of the song individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-intialize VADER\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# then split our song lyrics into lines broken up by newlines \n",
    "lines = lyrics.split('\\n') # note handy built-in python string function! \n",
    "\n",
    "# let's take a look\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the additional step of iterating through the list of lines and \n",
    "# calculating and printing polarity scores for each one.\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    scores = sid.polarity_scores(line)\n",
    "    for key in scores:\n",
    "        print('{0}: {1}, '.format(key, scores[key]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you’ll note a much more detailed picture of the sentiment in the song. \n",
    "\n",
    "* What seems interesting?\n",
    "* Did you notice any errors?\n",
    "* What are some research questions we could ask of our song lyrics corpus with sentiment analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
