{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I have built this notebook by adapting material from [a set of notebooks](https://melaniewalsh.github.io/Intro-Cultural-Analytics/features/Text-Analysis/Topic-Modeling.html) by Melanie Walsh on topic modeling from her online textbook [_Introduction to Cultural Analytics & Python_](https://melaniewalsh.github.io/Intro-Cultural-Analytics/features/welcome.html)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to learn about a text analysis method called **topic modeling**. This method will help us identify the main topics or discourses within a collection of texts (or within a single text that has been separated into smaller text chunks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we calculated term frequency-inverse document frequency (tf-idf) scores, we identified individual words that were more likely to show up in certain documents rather than in other ones. When we topic model, we're going to identify *clusters of words* that show up together in statistically meaningful ways throughout the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Are Topic Models Useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic models are useful for understanding collections of texts in their broadest outlines and themes. If you wanted to get a sense of the primary subjects discussed in thousands of journal articles published over multiple decades, then topic modeling might be a good choice. Topic models can also be helpful for looking at the fluctuation of topics and themes over time or finding clusters of texts that contain the same or similar topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these lessons, we will train a topic model on a collection of 378 obituaries published by *The New York Times*. As we'll find out, the topics--or clusters of words--that emerge from this analysis are broadly related to art, literature, sports, the military, and politics, among other subjects. These results are pretty satisfying! They seem to capture what the obituaries are \"about.\" Frida Kahlo's obituary contains a significant discussion of her art, while Nella Larsen's obituary discusses her novels, Jackie Robinson's obituary discusses his role in sports, and Ulysses S. Grant's obituary discusses his military career. How does the topic model \"know\" or \"discover\" what these *NYT* obituaries are about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How LDA Topic Models Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are numerous kinds of topic models, but the most popular and widely-used kind is latent Dirichlet allocation (LDA). It's so popular, in fact, that \"LDA\" and \"topic model\" are sometimes used interchangeably, even though LDA is only one type.\n",
    "\n",
    "LDA math is pretty complicated. We're not going to get very deep into the math here. But we are going to introduce two important concepts that will help us conceptually understand how LDA topic models work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) LDA is an Unsupervised Algorithm \n",
    "Topic modeling is a kind of machine learning. Machine learning always sounds like a fancy, scary term, but it really just means that computer algorithms are performing tasks without being explicitly programmed to do so and that they are \"learning\" how to perform these tasks by being fed training data. In the field of machine learning, algorithms are typically split into two broad categories: supervised and unsupervised. These categories describe how the algorithms are \"trained\" or how they \"learn.\" LDA is an unsupervised algorithm.\n",
    "\n",
    "If an algorithm is supervised, that means a researcher is helping to guide it with some kind of information, like labels. For example, if you wanted to create an algorithm that could identify pictures of cats vs pictures of dogs, you could train it with a bunch of pictures of cats that were clearly labeled CAT and a bunch of pictures of dogs that were clearly labeled DOG. The algorithm would then be able to learn which features are specific to cats vs dogs because you explicitly told it: this is a picture of a cat; this is a picture of a dog.\n",
    "\n",
    "If an algorithm is unsupervised, that means a researcher does not train it with outside information. There are no labels. The algorithm just learns that pictures of cats are more similar to each other and pictures of dogs are more similar to each other. The algorithm doesn't really know that one cluster is cats and one cluster is dogs; it just knows that there are two distinct clusters.\n",
    "\n",
    "Because LDA is an unsupervised algorithm, we don't tell our topic model which words or topics to look for. We only tell the topic model how many topics (or clusters of words) that we want returned. The topic model doesn't know anything about Frida Kahlo, Nella Larsen, and Jackie Robinson. It doesn't know anything about art, literature, and sports.\n",
    "\n",
    "### 2) LDA is a Probabilistic Model \n",
    "LDA fundamentally relies on statistics and probabilities. Rather than calculating precise and unchanging metrics about a given corpus, a topic model makes a series of very sophisticated guesses about the corpus. These guesses will change slightly every time we run the topic model. This is important to remember as we analyze, interpret, and make arguments based on our results. All of our results in this lesson will be probabilities, and they'll change slightly every time we re-run the topic model.\n",
    "\n",
    "When we tell the topic model that we want to extract 15 topics from the NYT obituaries, here's what the topic model does:\n",
    "\n",
    "The topic model starts off with a slightly silly, backwards assumption. The topic model assumes that every single one of the 378 obituaries in the corpus was written by someone who exclusively drew their words from 15 mystery topics, or 15 clusters of words. To spin it in a slightly different way with a different medium, the topic model assumes that there was one master artist with 15 different paints on her palette, who created all the NYT obituaries by dipping her brush into these 15 paints alone, applying and blending them onto each canvas in different proportions. The topic model is trying to discover the 15 mystery topics that created all the NYT obituaries, as well as the mixture of these topics that makes up each individual NYT obituary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The topic model begins by taking a completely wild guess about the 15 topics, but then it iterates through all the words in all the documents and makes better and better guesses. If the word \"book\" keeps showing up with the words \"published\" and \"writing,\" and if all three words keep showing up in the same kinds of NYT obituaries, then the topic model starts to suspect that these three words should belong to the same topic. If the word \"film\" keeps showing up with \"Hollywood\" and \"actor,\" then the topic model suspects that they should belong to the same topic, too. The topic model finally arrives at its best guesses for the 15 topics that most likely created all the NYT obituaries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we call a \"topic\" is really just a list of the most probable words for that topic, which are sorted in descending order of probability. The most probable word for the topic is the first word. Here are some sample topics from a previous run on the *NYT* obituaries:\n",
    "\n",
    "✨Topic 3✨\n",
    "\n",
    "['book', 'new', 'wrote', 'work', 'published', 'art', 'years', 'writing', 'world', 'writer', 'books', 'novel', 'paris', 'life', 'story']\n",
    "\n",
    "✨Topic 6✨\n",
    "\n",
    "['president', 'state', 'court', 'roosevelt', 'justice', 'house', 'years', 'law', 'party', 'political', 'republican', 'senator', 'governor', 'democratic', 'campaign']\n",
    "\n",
    "✨Topic 10✨\n",
    "\n",
    "['miss', 'film', 'years', 'theater', 'broadway', 'movie', 'films', 'hollywood', 'stage', 'movies', 'actor', 'new', 'director', 'york', 'show']\n",
    "\n",
    "Topic models start to get more powerful when we, as human researchers, analyze the most probable words for every topic and summarize what these words have in common. This summary can then be used as a descriptive label for the topic. Remember, since an LDA topic model is an unsupervised algorithm, it doesn't know what these words mean in relationship to one another. It's up to us, as the human researchers, to make meaning out of the topics.\n",
    "\n",
    "For example, we might label the topics as follows:\n",
    "\n",
    "✨Topic 3: **Literature**✨\n",
    "\n",
    "['book', 'new', 'wrote', 'work', 'published', 'art', 'years', 'writing', 'world', 'writer', 'books', 'novel', 'paris', 'life', 'story']\n",
    "\n",
    "✨Topic 6: **Politics**✨\n",
    "\n",
    "['president', 'state', 'court', 'roosevelt', 'justice', 'house', 'years', 'law', 'party', 'political', 'republican', 'senator', 'governor', 'democratic', 'campaign']\n",
    "\n",
    "✨Topic 10: **Hollywood**✨\n",
    "\n",
    "['miss', 'film', 'years', 'theater', 'broadway', 'movie', 'films', 'hollywood', 'stage', 'movies', 'actor', 'new', 'director', 'york', 'show']\n",
    "\n",
    "But even when the topics are relatively straightforward, as these topics seem to be, they're still open to interpretation. For instance, we could just as easily label Topic 3 \"Writing & Art,\" Topic 6 \"Government,\" and Topic 10 \"Film & Theater.\" These subtle changes might shape the direction of our analysis and eventual argument in substantial ways. Topics can be far more ambiguous than the above examples, as well, which makes the business of interpretation even more significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MALLET & Little MALLET Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our topic modeling analysis, we're going to use a tool called [MALLET](http://mallet.cs.umass.edu/topics.php). MALLET, short for **MA**chine **L**earning for **L**anguag**E** **T**oolkit, is a software package for  topic modeling and other natural language processing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MALLET is great, but it's written in Java, another programming language. It also means that MALLET isn't typically ideal for Python and Jupyter notebooks.\n",
    "\n",
    "Luckily, Maria Antoniak, a PhD student in Information Science, has written a convenient Python package that will allow us to use MALLET in this Jupyter notebook. This package is called [Little MALLET Wrapper](https://github.com/maria-antoniak/little-mallet-wrapper).\n",
    "\n",
    "Note: A \"wrapper\" is a Python package that makes complicated code easier to use and/or makes code from a different programming language accessible in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *New York Times* Obituaries\n",
    "\n",
    "In this lesson, we're going to use [Little MALLET Wrapper](https://github.com/maria-antoniak/little-mallet-wrapper) to topic model 378 obituaries published by *The New York Times*. This dataset is based on data originally collected by Matt Lavin for his *Programming Historian* [TF-IDF tutorial](https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf#lesson-dataset). Melanie Walsh re-scraped the obituaries so that the subject's name and death year are included in each text file name; she also added 12 more [\"Overlooked\"](https://www.nytimes.com/interactive/2018/obituaries/overlooked.html) obituaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MALLET Path\n",
    "```{attention}\n",
    "If you're working in this Jupyter notebook on your own computer, you'll need to have both the Java Development Kit and MALLET pre-installed. For set up instructions, please see [this lesson](http://melaniewalsh.github.io/Intro-Cultural-Analytics/Text-Analysis/Topic-Modeling-Set-Up.html).\n",
    "\n",
    "If you're working on JupyterHub, then the Java Development Kit and Mallet will already be installed.\n",
    "```\n",
    "Since Little MALLET Wrapper is a Python package built around MALLET, we first need to tell it where the bigger, Java-based MALLET lives.\n",
    "\n",
    "We're going to make a variable called `path_to_mallet` and assign it the file path of our MALLET program. We need to point it, specifically, to the \"mallet\" file inside the \"bin\" folder inside the \"mallet-2.0.8\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mallet = '/data/mallet/bin/mallet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If MALLET is located in another directory, then set your `path_to_mallet` to that file path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are pre-installed in JupyterHub\n",
    "#!pip install little_mallet_wrapper\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's `import` the `little_mallet_wrapper` and the data viz library `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to import [`glob`](https://docs.python.org/3/library/glob.html) and [`pathlib`](https://docs.python.org/3/library/pathlib.html#basic-use) for working with files and the file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we topic model the *NYT* obituaries, we need to pre-process the text files to prepare them for analysis. \n",
    "\n",
    "```{note}\n",
    "We're calling these text files our *training data*, because we're *training* our topic model with these texts. The topic model will be learning and extracting topics based on these texts.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the necessary text files, we're going to make a variable and assign it the file path for the directory that contains the text files. \n",
    "\n",
    "_If the below line doesn't work, you might need to [download](https://canvas.emory.edu/courses/76593/files/4268875?module_item_id=1056761) the files from Canvas and direct to the path where it lives_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../docs/NYT-Obituaries/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're going to use the `glob.gob()` function to make a list of all (`*`) the `.txt` files in that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f\"{directory}/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we process our texts with the function `little_mallet_wrapper.process_string()`. This function will take every individual text file, transform all the text to lowercase as well as remove stopwords, punctuation, and numbers, and then add the processed text to our master list `training_data`.\n",
    "\n",
    "Python Review!\n",
    "Take a moment to study this code and reflect about what's happening here. This is a very common Python pattern! We make an empty list, iterate through every file, open and read each text file, process the texts, and finally append them to the previously empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for file in files:\n",
    "    text = open(file, encoding='utf-8').read()\n",
    "    processed_text = little_mallet_wrapper.process_string(text, numbers='remove')\n",
    "    training_data.append(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also making a master list of the original text of the obituaries for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = []\n",
    "for file in files:\n",
    "    text = open(file, encoding='utf-8').read()\n",
    "    original_texts.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract the relevant part of each file name by using [`Path().stem`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.stem), which conveniently extracts just the last part of the file path without the \".txt\" file extension. Because each file name includes the obituary subject's name as well as the year that the subject died, we're going to use this information as a title or label for each obituary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obit_titles = [Path(file).stem for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obit_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Data Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get training data summary statistics by using the function ```little_mallet_wrapper.print_dataset_stats()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_mallet_wrapper.print_dataset_stats(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this little report, we have 378 documents (or obituaries) that average 1316.5 words in length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to train our topic model with the `little_mallet_wrapper.train_topic_model()` function. As you can see above, however, this function requires 6 different arguments and file paths to run properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a variable `num_topics` and assign it the number of topics we want returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already made a variable called `training_data`, which includes all of our processed obituary texts, so we can just set it equal to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Topic Model Output Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to tell Little MALLET Wrapper where to find and output all of our topic modeling results. The code below will set Little MALLET Wrapper up to output your results inside a directory called \"topic-model-output\" and a subdirectory called \"NYT-Obits\", all of which will be inside your current directory.\n",
    "\n",
    "If you'd like to change this output location, simply change `output_directory_path` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to your desired output directory\n",
    "output_directory_path = 'topic-model-output/NYT-Obits'\n",
    "\n",
    "#No need to change anything below here\n",
    "Path(f\"{output_directory_path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_to_training_data           = f\"{output_directory_path}/training.txt\"\n",
    "path_to_formatted_training_data = f\"{output_directory_path}/mallet.training\"\n",
    "path_to_model                   = f\"{output_directory_path}/mallet.model.{str(num_topics)}\"\n",
    "path_to_topic_keys              = f\"{output_directory_path}/mallet.topic_keys.{str(num_topics)}\"\n",
    "path_to_topic_distributions     = f\"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import our training data with `little_mallet_wrapper.import_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_mallet_wrapper.import_data(path_to_mallet,\n",
    "                path_to_training_data,\n",
    "                path_to_formatted_training_data,\n",
    "                training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train our topic model with `little_mallet_wrapper.train_topic_model()`. The topic model should take about 45 seconds to 1 minute to fully train and complete. If you want, you can look at your Terminal or PowerShell while it's running and see what the model looks like as it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_mallet_wrapper.train_topic_model(path_to_mallet,\n",
    "                      path_to_formatted_training_data,\n",
    "                      path_to_model,\n",
    "                      path_to_topic_keys,\n",
    "                      path_to_topic_distributions,\n",
    "                      num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the topic model finishes, it will output your results to your `output_directory_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Topics and Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the 15 topics that the topic model extracted from the *NYT* obituaries, run the cell below. This code uses the `little_mallet_wrapper.load_topic_keys()` function to read and process the MALLET topic model output from your computer, specifically the file \"mallet.topic_keys.15\".\n",
    "\n",
    ">*Take a minute to read through every topic. Reflect on what each topic seems to capture as well as how well you think the topics capture the broad themes of the entire collection. Note any oddities, outliers, or inconsistencies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "\n",
    "for topic_number, topic in enumerate(topics):\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Topic Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MALLET also calculates the likely mixture of these topics for every single obituary in the corpus. This mixture is really a probability distribution, that is, the probability that each topic exists in the document. We can use these probability distributions to examine which of the above topics are strongly associated with which specific obituaries.\n",
    "\n",
    "To get the topic distributions, we're going to use the `little_mallet_wrapper.load_topic_distributions()` function, which will read and process the MALLET topic model output, specifically the file \"mallet.topic_distributions.15\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the 32nd topic distribution in this list of `topic_distributions`, which corresponds to Marilyn Monroe's obituary, we will see a list of 15 probabilities. This  list corresponds to the likelihood that each of the 15 topics exists in Marilyn Monroe's obituary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit easier to understand if we pair these probabilities with the topics themselves. As you can see below, Topic 0 \"miss film theater movie broadway films\" has a relatively high probability of existing in Marilyn Monroe's obituary `.202` while Topic 5 \"soviet hitler german germany stalin union\" has a relatively low probability `.002`. This seems to comport with what we know about Marilyn Monroe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obituary_to_check = \"1962-Marilyn-Monroe\"\n",
    "\n",
    "obit_number = obit_titles.index(obituary_to_check)\n",
    "\n",
    "print(f\"Topic Distributions for {obit_titles[obit_number]}\\n\")\n",
    "for topic_number, (topic, topic_distribution) in enumerate(zip(topics, topic_distributions[obit_number])):\n",
    "    print(f\"✨Topic {topic_number} {topic[:6]} ✨\\nProbability: {round(topic_distribution, 3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Heatmap of Topics and Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize and compare these topic probability distributions with a heatmap by using the `little_mallet_wrapper.plot_categories_by_topics_heatmap()` function.\n",
    "\n",
    "We have everything we need for the heatmap except for our list of target_labels, the sample of texts that we’d like to visualize and compare with the heatmap. Below we make our list of desired target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = ['1852-Ada-Lovelace', '1885-Ulysses-Grant',\n",
    "                 '1900-Nietzsche', '1931-Ida-B-Wells', '1940-Marcus-Garvey',\n",
    "                 '1941-Virginia-Woolf', '1954-Frida-Kahlo', '1962-Marilyn-Monroe',\n",
    "                 '1963-John-F-Kennedy', '1964-Nella-Larsen', '1972-Jackie-Robinson',\n",
    "                 '1973-Pablo-Picasso', '1984-Ray-A-Kroc','1986-Jorge-Luis-Borges', '1991-Miles-Davis',\n",
    "                 '1992-Marsha-P-Johnson', '1993-Cesar-Chavez']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to make a random list of target labels, you can uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "#target_labels = random.sample(obit_titles, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_mallet_wrapper.plot_categories_by_topics_heatmap(obit_titles,\n",
    "                                      topic_distributions,\n",
    "                                      topics, \n",
    "                                      output_directory_path + '/categories_by_topics.pdf',\n",
    "                                      target_labels=target_labels,\n",
    "                                      dim= (10, 9)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The darker squares in this heatmap represent a high probability for the corresponding topic (compared to everyone else in the heatmap) and the lighter squares in the heatmap represent a low probability for the corresponding topic. For example, if you scan across the row of Marilyn Monroe, you can see a dark square for the topic \"miss film theater movie theater broadway\". If you scan across the row of Ada Lovelace, an English mathematician who is now recognized as the first computer programmer, according to her [NYT obituary](https://www.nytimes.com/interactive/2018/obituaries/overlooked-ada-lovelace.html), you can see a dark square for \"university professor research science also\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Top Titles Per Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display the obituaries that have the highest probability for every topic with the `little_mallet_wrapper.get_top_docs()` function.\n",
    "\n",
    "Because most of the obituaries in our corpus are pretty long, however, it will be more useful for us to simply display the title of each obituary, rather than the entire document—at least as a first step. To do so, we'll first need to make two dictionaries, which will allow us to find the corresponding obituary title and the original text from a given training document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_obit_titles = dict(zip(training_data, obit_titles))\n",
    "training_data_original_text = dict(zip(training_data, original_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll make our own function `display_top_titles_per_topic()` that will display the top text titles for every topic. This function accepts a given `topic_number` as well as a desired `number_of_documents` to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_titles_per_topic(topic_number=0, number_of_documents=5):\n",
    "    \n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        print(round(probability, 4), training_data_obit_titles[document] + \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the top 5 obituary titles with the highest probability of containing Topic 0, we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_titles_per_topic(topic_number=0, number_of_documents=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 0 Label**: What label would you give this topic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the top 5 obituary titles with the highest probability of containing Topic 9, we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_titles_per_topic(topic_number=9, number_of_documents=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 9 Label**: What label would you give this topic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Topic Words in Context of Original Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it's useful to actually look at the document that has ranked highly for a given topic and puzzle out why it ranks so highly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the original obituary texts that rank highly for a given topic, with the relevant topic words **bolded** for emphasis, we are going to make the function `display_bolded_topic_words_in_context()`.\n",
    "\n",
    "In the cell below, we're importing two special Jupyter notebook display modules, which will allow us to make the relevant topic words **bolded**, as well as the regular expressions library `re`, which will allow us to find and replace the correct words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def display_bolded_topic_words_in_context(topic_number=3, number_of_documents=3, custom_words=None):\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        \n",
    "        print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "        \n",
    "        probability = f\"✨✨✨\\n\\n**{probability}**\"\n",
    "        obit_title = f\"**{training_data_obit_titles[document]}**\"\n",
    "        original_text = training_data_original_text[document]\n",
    "        topic_words = topics[topic_number]\n",
    "        topic_words = custom_words if custom_words != None else topic_words\n",
    "\n",
    "        for word in topic_words:\n",
    "            if word in original_text:\n",
    "                original_text = re.sub(f\"\\\\b{word}\\\\b\", f\"**{word}**\", original_text)\n",
    "\n",
    "        display(Markdown(probability)), display(Markdown(obit_title)), display(Markdown(original_text))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the top 3 original obituaries with the highest probability of containing Topic 0 and with relevant topic words bolded, we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bolded_topic_words_in_context(topic_number=3, number_of_documents=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the top 3 original obituaries with the highest probability of containing Topic 8 and with relevant topic words bolded, we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bolded_topic_words_in_context(topic_number=8, number_of_documents=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a topic from the results above and write down its corresponding topic number below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic: *Your Number Choice Here***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Display the top 6 obituary titles for this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Display the topic words in the context of the original obituary for these 6 top titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Come up with a label for your topic and write it below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Label: *Your Label Here***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Why did you label your topic the way you did? What do you think this topic means in the context of all the *NYT* obituaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#**Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** What's another collection of texts that you think might be interesting to topic model? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#**Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to explore further, try returning to the top and replacing the obituaries with the lyrics corpus and/or changing the number of topics from 15 to other numbers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
