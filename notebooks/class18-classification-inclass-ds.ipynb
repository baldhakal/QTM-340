{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification, a method popular in machine learning, determines whether and how a model can distinguish between to sets of text.\n",
    "\n",
    "It works like this. Everyone with email relies on classification to separate spam from legitimate emails. Email providers train their computational models to recognize the difference by giving them emails they have labeled “spam” and “not spam.” They then ask the model to learn the features that most reliably distinguish the two types, which could include a preponderance of all caps or phrases like “free money” or “get paid.” They test the model by giving it unlabeled emails and asking it to classify them. If the model can do it accurately a high percentage of the time, that’s a good spam filter.\n",
    "\n",
    "We can take the underlying idea and apply it to many experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "As always, we begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../docs/NYT-Obituaries/\"\n",
    "files = glob.glob(f\"{directory}/*.txt\")\n",
    "obit_titles = [Path(file).stem for file in files]\n",
    "obit_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dtm\n",
    "corpus_path = '../docs/NYT-Obituaries/'\n",
    "vectorizer = CountVectorizer(input='filename', encoding='utf8', stop_words = new_stopwords, min_df=40, dtype='float64')\n",
    "corpus = []\n",
    "for title in obit_titles:\n",
    "    filename = title + \".txt\"\n",
    "    corpus.append(corpus_path + filename)\n",
    "dtm = vectorizer.fit_transform(corpus)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "matrix = dtm.toarray()\n",
    "df = DataFrame(matrix, columns=vocab)\n",
    "print('df shape is: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../docs/NYT-Obituaries.csv\", encoding = 'utf-8')\n",
    "meta = meta[[\"title\", \"gender\", \"date\"]]\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "text_file = open('../docs/jockers_stopwords.txt')\n",
    "jockers_words = text_file.read().split()\n",
    "new_stopwords = text.ENGLISH_STOP_WORDS.union(jockers_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([meta, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE FOR ONE VS ALL CLASSIFICATION\n",
    "\n",
    "meta['PROBS'] = ''\n",
    "meta['PREDICTED'] = ''\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', C = 1.0)\n",
    "\n",
    "for this_index in df_final.index.tolist():\n",
    "    print(this_index)\n",
    "    title = meta.loc[meta.index[this_index], 'title'] \n",
    "    CLASS = meta.loc[meta.index[this_index], 'gender']\n",
    "    print(title, CLASS)\n",
    "    train_index_list = [index_ for index_ in df.index.tolist() if index_ != this_index]\n",
    "\n",
    "    X = df.loc[train_index_list]\n",
    "    y = meta.loc[train_index_list, 'gender']\n",
    "    TEST_CASE = df.loc[[this_index]]\n",
    "\n",
    "    model.fit(X,y)\n",
    "    prediction = model.predict_proba(TEST_CASE)\n",
    "    predicted = model.predict(TEST_CASE)\n",
    "    meta.at[this_index, 'PREDICTED'] = predicted\n",
    "    meta.at[this_index, 'PROBS'] = str(prediction)\n",
    "    print('Class is: ' + str(CLASS) + '\\n' + 'Prediction is: ' + str(predicted) + ' ' + str(prediction) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonic_c = 1.0\n",
    "\n",
    "def Ztest(vec1, vec2):\n",
    "\n",
    "    X1, X2 = np.mean(vec1), np.mean(vec2)\n",
    "    sd1, sd2 = np.std(vec1), np.std(vec2)\n",
    "    n1, n2 = len(vec1), len(vec2)\n",
    "\n",
    "    pooledSE = np.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = (X1 - X2)/pooledSE\n",
    "    pval = 2*(norm.sf(abs(z)))\n",
    "\n",
    "    return z, pval\n",
    "\n",
    "def feat_pval_weight(meta_df_, dtm_df_):\n",
    "    \n",
    "    #dtm_df_ = dtm_df_.loc[meta_df_.index.tolist()]\n",
    "    #dtm_df_ = normalize_model(dtm_df_, dtm_df_)[0]\n",
    "    #dtm_df_ = dtm_df_.dropna(axis = 1, how='any')\n",
    "\n",
    "    dtm0 = dtm_df_.loc[meta_df_[meta_df_['gender']==0].index.tolist()].to_numpy()\n",
    "    dtm1 = dtm_df_.loc[meta_df_[meta_df_['gender']==1].index.tolist()].to_numpy()\n",
    "\n",
    "    pvals = [Ztest(dtm0[ : ,i], dtm1[ : ,i])[1] for i in range(dtm_df_.shape[1])]\n",
    "    clf = LogisticRegression(penalty = 'l1', C = canonic_c, class_weight = 'balanced')\n",
    "    clf.fit(dtm_df_, meta_df_['gender']==0)\n",
    "    weights = clf.coef_[0]\n",
    "\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    feature_df['FEAT'] = dtm_df_.columns\n",
    "    feature_df['P_VALUE'] = pvals\n",
    "    feature_df['LR_WEIGHT'] = weights\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "sig_thresh = 0.05 / len(df.columns)\n",
    "\n",
    "feat_df = feat_pval_weight(meta, df)\n",
    "\n",
    "feat_df.to_csv('../docs/features_obits.csv')\n",
    "out = feat_df[(feat_df['P_VALUE'] <= sig_thresh)].sort_values('LR_WEIGHT', ascending = True)\n",
    "out = out[out['LR_WEIGHT'] != 0]\n",
    "outM = out[out['LR_WEIGHT'] >= 0]\n",
    "outW = out[out['LR_WEIGHT'] <= 0]\n",
    "\n",
    "outM = outM['FEAT'].tolist()\n",
    "print(\"Here are significant words that distinguish men: \" + str(outM))\n",
    "outW = outW['FEAT'].tolist()\n",
    "print(\"Here are significant words that distinguish women: \" + str(outW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframe\n",
    "\n",
    "For classification, we need two kinds of things: text and classes (e.g. gender, race, publisher). Pandas dataframes are useful for classification because they can hold a complete text and its metadata in a single row.\n",
    "\n",
    "For this lesson, we're going to use our _New York Times_ obituaries corpus, which I have supplemented with the gender of the person who died and the date of publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many words are uninteresting or unhelpful for classification, so we treat them as stopwords and remove them from the corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
