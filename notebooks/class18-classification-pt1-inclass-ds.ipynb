{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification, Pt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification, a method popular in machine learning, determines whether and how a model can distinguish between sets of text.\n",
    "\n",
    "It works like this. Everyone with email relies on classification to separate spam from legitimate emails. Email providers train classification models to recognize the difference by giving them emails they have labeled “spam” and “not spam.” They then ask the model to learn the features that most reliably distinguish the two types, which could include a preponderance of all caps or phrases like “free money” or “get paid.” They test the model by giving it unlabeled emails and asking it to classify them. If the model can do it accurately a high percentage of the time, that’s a good spam filter.\n",
    "\n",
    "We can take the underlying idea and apply it to many experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use our _New York Times_ obituaries corpus to test whether our model can learn to distinguish between obituaries about men and women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "As always, we begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from pandas import DataFrame\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import pearsonr, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we'll return to our corpus of _New York Times_ obituaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect filepaths as files\n",
    "directory = \"../docs/NYT-Obituaries/\"\n",
    "files = glob.glob(f\"{directory}/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and collect obit titles, which are also the final section of the filepaths\n",
    "obit_titles = [Path(file).stem for file in files]\n",
    "obit_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate CountVectorizer as vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember document-term matrices, aka doc-term matrices, aka dtms? We learned about them in notebooks 10 and 11. Our classifier uses a dtm as its input. We build it with scikit-learn's CountVectorizer, which we imported at the start of the lesson. \n",
    "\n",
    "When we load our vectorizer, we include an argument to encode as utf-8 and we load our stopwords. We can also set the minimum number of times a word must appear in the corpus to be included in the dtm. In this case, I've set it at 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "text_file = open('../docs/jockers_stopwords.txt')\n",
    "jockers_words = text_file.read().split()\n",
    "new_stopwords = text.ENGLISH_STOP_WORDS.union(jockers_words)\n",
    "\n",
    "# create dtm\n",
    "corpus_path = '../docs/NYT-Obituaries/'\n",
    "vectorizer = CountVectorizer(input='filename', encoding='utf8', stop_words = new_stopwords, min_df=20, dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make list of filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer builds a dtm from a list of filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for title in obit_titles:\n",
    "    filename = title + \".txt\"\n",
    "    corpus.append(corpus_path + filename)\n",
    "dtm = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature names and set as column titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns store word counts. We want to name the columns with the words stored in each, and to transform the dtm into a pandas dataframe, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "matrix = dtm.toarray()\n",
    "df = DataFrame(matrix, columns=vocab)\n",
    "print('df shape is: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframee has 378 rows, one for each document, or obituary, and 2985 columns, one for each word that's not in stopwords and appears at least 20 times in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../docs/NYT-Obituaries.csv\", encoding = 'utf-8')\n",
    "meta = meta.rename(columns={'title': 'obit_title'})\n",
    "meta = meta[[\"obit_title\", \"gender\", \"date\"]]\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our metadata is stored as a pandas dataframe with a row for each obituary and three columns: title, gender, and year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate metadata and doc-term dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([meta, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalize numbers of men and women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our dataframe to have equal numbers of men and women. How many women are there? Women are counted as 1 and men as 0, so if we sum the gender column, we'll have the number of women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['gender'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate men and women into two dataframes and take a random sample of 93 obituaries about men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_men = df_concat[df_concat['gender'] == 0]\n",
    "df_women = df_concat[df_concat['gender'] == 1]\n",
    "df_men = df_men.sample(n=93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then concatenate the sampled men dataframe with the women dataframe and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_men, df_women])\n",
    "df_final = df_final.reset_index()\n",
    "df_final = df_final.drop(columns=\"index\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 186 rows: 93 men, 93 women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match meta and data dataframes with subset of df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue to use meta and df, so we need to ensure they match our subsetted df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = df_final[[\"obit_title\", \"gender\", \"date\"]]\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.loc[:,'000':]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a dataframe with metadata and vocab counts we're ready to run our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We add columns for probabilities and predicted class to our metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we run the model, we are going to store its output with our metadata. This will allow us to easily examine the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['PROBS'] = ''\n",
    "meta['PREDICTED'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use scikit-learn's `LogisticRegression` model. There are many other options for classifier models. Some are better for some tasks, other for others. LogisticRegression is standard for classifying literature. We set the penalty as l1 and the 'C' value as 1.0. If you decide to specialize in classification, you can explore further the implications of these arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty = 'l1', C = 1.0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the model in the following for-loop.\n",
    "\n",
    "Classification models need classes: they need the texts grouped into different sets. Our metadata has built-in classes: gender. Men are stored as 0; women as 1. We could, if we wanted, create a new 0/1 class based on year.\n",
    "\n",
    "Each iteration trains on all the titles except one, then predicts which class the excluded title belongs to. We'll call this leave-one-out classification. There are other ways of dividing training and testing sets, which we won't explore today.\n",
    "\n",
    "The first four indented lines simply track our progress by printing index, title, and class. The next four lines exclude a single title, and set the training data and the test data.\n",
    "\n",
    "The final six lines fit the model, calculate the probabilities and predicted class of the test case, and add that information to our metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_index in df_final.index.tolist():\n",
    "    print(this_index) # keep track of where we are in the corpus\n",
    "    title = meta.loc[meta.index[this_index], 'obit_title'] \n",
    "    CLASS = meta.loc[meta.index[this_index], 'gender']\n",
    "    print(title, CLASS) \n",
    "    \n",
    "    train_index_list = [index_ for index_ in df.index.tolist() if index_ != this_index] # exclude the title to be predicted\n",
    "    X = df.loc[train_index_list] # the model trains on all the data except the excluded title row\n",
    "    y = meta.loc[train_index_list, 'gender'] # the y row tells the model which class each title belongs to\n",
    "    TEST_CASE = df.loc[[this_index]]\n",
    "\n",
    "    model.fit(X,y) # fit the model\n",
    "    prediction = model.predict_proba(TEST_CASE) # calculate probability of test case\n",
    "    predicted = model.predict(TEST_CASE) # calculate predicted class of test case\n",
    "    meta.at[this_index, 'PREDICTED'] = predicted # add predicted class to metadata\n",
    "    meta.at[this_index, 'PROBS'] = str(prediction) # add probabilities to metadata\n",
    "    print('Class is: ' + str(CLASS) + '\\n' + 'Prediction is: ' + str(predicted) + ' ' + str(prediction) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How cool is this! For each obituary, we see who it's about, that person's gender (0 or 1), and which gender the model thinks it's about, by which probabilities. \n",
    "\n",
    "What can you glean by glancing through?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE\n",
    "* *\n",
    "* *\n",
    "* *\n",
    "* *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we've stored our results in our metadata dataframe. Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's lots to look at here. We could explore probabilities: which obituaries is the model most sure about? Which are closest to 50-50? Which does it get most right and most wrong? Is there a pattern to misclassified obituaries?\n",
    "\n",
    "For now, we just want to calculate its accuracy. Let's get rid of those brackets in the PREDICTED column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.replace([0], 0)\n",
    "meta = meta.replace([1], 1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add a 'RESULT' column that is the result of subtracting the predicted gender from the actual gender.\n",
    "\n",
    "0 means the model was correct.\n",
    "-1 means the model mistook a man for a woman.\n",
    "1 means the model mistook a woman for a man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_column = meta['gender'] - meta['PREDICTED']\n",
    "meta['RESULT'] = sum_column\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the accurate guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta[meta['RESULT'] == 0]\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many did the model get correct?\n",
    "\n",
    "We can calculate its accuracy by dividing the correct number by the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good rate! At random, the model should guess correctly 50% of the time. It does **much** better than that!\n",
    "\n",
    "In the next lesson, we'll explore _how_ the model made its calculations by learning which words matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to explore further, divide the obituaries by year rather than gender. You'll need to do some data clearning and some manipulation of pandas to make it work. Can you figure it out?\n",
    "\n",
    "If you're feeling REALLY ambitious, you can use this notebook and the next one to run classification over your own data. All you need is a text corpus with binary metadata (that is, metadata that can be divided into two classes). Classification works best if you have at least around eighty texts of each class, so our lyrics corpus is too small (though you could try and see what happens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
